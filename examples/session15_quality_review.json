{
  "session": 15,
  "date": "2026-02-08",
  "review_scope": "Top 20 high-confidence matches (≥0.7 similarity)",
  "total_reviewed": 20,
  "methodology": "Manual review of pattern descriptions, paper titles, and domain context",

  "summary": {
    "excellent": 6,
    "good": 4,
    "medium": 3,
    "weak": 7,
    "precision": "50% (10/20 are good or excellent)",
    "notes": "Quality consistent with Sessions 10-12. Top matches (>0.9) are excellent. Fine-tuning matches are weak (generic methodological overlap without structural isomorphism)."
  },

  "detailed_assessment": [
    {
      "id": 151015,
      "score": 0.9375,
      "mechanism": "scaling",
      "domains": "cs ↔ cond-mat",
      "paper1": "Inverse Depth Scaling (LLMs)",
      "paper2": "Broken neural scaling laws (materials science)",
      "quality": "EXCELLENT",
      "reasoning": "Both papers examine neural scaling laws - one in LLMs, one in materials science. Genuine structural isomorphism of scaling law theory applied to different domains.",
      "cross_domain": true
    },
    {
      "id": 151016,
      "score": 0.932,
      "mechanism": "scaling",
      "domains": "cs ↔ cond-mat",
      "paper1": "Inverse Depth Scaling (LLMs)",
      "paper2": "Broken neural scaling laws (materials science)",
      "quality": "EXCELLENT",
      "reasoning": "Same pair as above - neural scaling laws framework appearing in both CS and materials science.",
      "cross_domain": true
    },
    {
      "id": 151017,
      "score": 0.926,
      "mechanism": "network_effect",
      "domains": "cond-mat ↔ q-bio",
      "paper1": "DMFlow: GNN for materials generation",
      "paper2": "MGKAN: GNN for drug-drug interactions",
      "quality": "EXCELLENT",
      "reasoning": "Both use Graph Neural Networks (GNNs) to learn from structured data - one for materials, one for drug interactions. Same methodology for different molecular problems.",
      "cross_domain": true
    },
    {
      "id": 151018,
      "score": 0.925,
      "mechanism": "network_effect",
      "domains": "stat ↔ q-bio",
      "paper1": "CFRecs: GNN for recommendations",
      "paper2": "MGKAN: GNN for drug-drug interactions",
      "quality": "EXCELLENT",
      "reasoning": "Both apply GNNs to different domains - recommendation systems vs drug interactions. Genuine cross-domain application of graph learning.",
      "cross_domain": true
    },
    {
      "id": 151019,
      "score": 0.921,
      "mechanism": "network_effect",
      "domains": "stat ↔ cond-mat",
      "paper1": "CFRecs: GNN for recommendations",
      "paper2": "DMFlow: GNN for materials",
      "quality": "EXCELLENT",
      "reasoning": "GNN methodology applied to recommendation systems and materials generation. Strong methodological isomorphism.",
      "cross_domain": true
    },
    {
      "id": 151020,
      "score": 0.825,
      "mechanism": "fine_tuning",
      "domains": "cs ↔ q-bio",
      "paper1": "PIRATR: Robotics fine-tuning",
      "paper2": "ProDCARL: Drug design fine-tuning",
      "quality": "WEAK",
      "reasoning": "Generic fine-tuning methodology overlap. Pattern descriptions are just numbers ('0.919 without fine-tuning', '0.081 after fine-tuning') without structural insight. Not a true isomorphism.",
      "cross_domain": false
    },
    {
      "id": 151021,
      "score": 0.815,
      "mechanism": "scaling",
      "domains": "cond-mat ↔ physics",
      "paper1": "Broken neural scaling laws (materials)",
      "paper2": "iCIPT2: Power law scaling (quantum physics)",
      "quality": "GOOD",
      "reasoning": "Both examine scaling law relationships - one in neural networks for materials, one in quantum chemistry errors. Different contexts but same mathematical pattern (power law).",
      "cross_domain": true
    },
    {
      "id": 151022,
      "score": 0.80,
      "mechanism": "fine_tuning",
      "domains": "cs ↔ q-bio",
      "paper1": "Vision language models fine-tuning",
      "paper2": "Drug design fine-tuning",
      "quality": "WEAK",
      "reasoning": "Generic fine-tuning overlap without structural similarity. One is about vision models, other is drug design. Methodology only.",
      "cross_domain": false
    },
    {
      "id": 151023,
      "score": 0.797,
      "mechanism": "fine_tuning",
      "domains": "biology ↔ cs",
      "paper1": "Brain network foundation models fine-tuning",
      "paper2": "Vision models fine-tuning",
      "quality": "WEAK",
      "reasoning": "Both mention fine-tuning strategies but lack structural similarity beyond generic ML methodology.",
      "cross_domain": false
    },
    {
      "id": 151024,
      "score": 0.793,
      "mechanism": "scaling",
      "domains": "stat ↔ cond-mat",
      "paper1": "Optimal scaling laws (hierarchical models)",
      "paper2": "Neural scaling laws (materials science)",
      "quality": "EXCELLENT",
      "reasoning": "Sharp theoretical foundations for scaling laws (math/stats) matched with empirical neural scaling laws (materials science). Theory meets application - genuine isomorphism.",
      "cross_domain": true
    },
    {
      "id": 151025,
      "score": 0.7875,
      "mechanism": "fine_tuning",
      "domains": "biology ↔ cs",
      "paper1": "Brain networks fine-tuning",
      "paper2": "Robotics fine-tuning",
      "quality": "WEAK",
      "reasoning": "Generic fine-tuning overlap. Pattern descriptions lack structural content.",
      "cross_domain": false
    },
    {
      "id": 151026,
      "score": 0.7875,
      "mechanism": "fine_tuning",
      "domains": "biology ↔ q-bio",
      "paper1": "Brain networks fine-tuning",
      "paper2": "Drug design fine-tuning",
      "quality": "WEAK",
      "reasoning": "Generic methodological overlap without structural similarity.",
      "cross_domain": false
    },
    {
      "id": 151027,
      "score": 0.786,
      "mechanism": "optimization",
      "domains": "cs ↔ physics",
      "paper1": "Quantum RL for routing (hybrid quantum-classical)",
      "paper2": "Tensor networks for ground-state (spin glasses)",
      "quality": "GOOD",
      "reasoning": "Both use hybrid quantum-classical optimization for combinatorial problems. One for routing (CVRP), one for spin glass ground states. Shared computational approach to hard optimization.",
      "cross_domain": true
    },
    {
      "id": 151028,
      "score": 0.786,
      "mechanism": "combinatorial",
      "domains": "cs ↔ physics",
      "paper1": "Quantum RL (CVRP)",
      "paper2": "Tensor networks (spin glasses)",
      "quality": "GOOD",
      "reasoning": "Same paper pair - both tackle combinatorial optimization problems with quantum-enhanced methods.",
      "cross_domain": true
    },
    {
      "id": 151029,
      "score": 0.782,
      "mechanism": "adaptation",
      "domains": "cs ↔ cs",
      "paper1": "FOVI: kNN-convolutional architecture",
      "paper2": "Layer-wise LoRA fine-tuning",
      "quality": "MEDIUM",
      "reasoning": "Both involve adaptation mechanisms (kNN-conv vs LoRA) but in different contexts. Some structural similarity in parameter-efficient adaptation but not a strong isomorphism.",
      "cross_domain": false
    },
    {
      "id": 151030,
      "score": 0.78,
      "mechanism": "fine_tuning",
      "domains": "cs ↔ q-bio",
      "paper1": "Hate speech benchmarks fine-tuning",
      "paper2": "Drug design fine-tuning",
      "quality": "WEAK",
      "reasoning": "Generic fine-tuning overlap. No structural similarity.",
      "cross_domain": false
    },
    {
      "id": 151031,
      "score": 0.779,
      "mechanism": "adaptation",
      "domains": "cs ↔ cs",
      "paper1": "Shared LoRA for continual learning",
      "paper2": "FOVI: kNN-convolutional adaptation",
      "quality": "MEDIUM",
      "reasoning": "Both use adaptation for parameter efficiency but different mechanisms (LoRA vs kNN). Moderate structural overlap.",
      "cross_domain": false
    },
    {
      "id": 151032,
      "score": 0.779,
      "mechanism": "scaling",
      "domains": "cs ↔ q-bio",
      "paper1": "Inverse Depth Scaling (LLMs)",
      "paper2": "Molecular language models scaling",
      "quality": "GOOD",
      "reasoning": "Both examine scaling behaviors in language models - one for natural language, one for molecular sequences. Similar theoretical framework applied to different sequence types.",
      "cross_domain": true
    },
    {
      "id": 151033,
      "score": 0.779,
      "mechanism": "scaling",
      "domains": "cond-mat ↔ stat",
      "paper1": "Broken neural scaling (materials)",
      "paper2": "Mandelbrot: scaling and self-similarity",
      "quality": "GOOD",
      "reasoning": "Both papers examine scaling concepts - one in neural networks, one in fractal/self-similar systems. Shared mathematical pattern of scaling behavior.",
      "cross_domain": true
    },
    {
      "id": 151034,
      "score": 0.779,
      "mechanism": "scaling",
      "domains": "cond-mat ↔ stat",
      "paper1": "Broken neural scaling (materials)",
      "paper2": "Mandelbrot: scaling and self-similarity",
      "quality": "GOOD",
      "reasoning": "Duplicate of above - scaling laws in different contexts.",
      "cross_domain": true
    }
  ],

  "patterns_identified": {
    "strong_signal_mechanisms": [
      "scaling (especially neural scaling laws)",
      "network_effect (especially Graph Neural Networks)",
      "combinatorial optimization",
      "quantum-classical hybrid methods"
    ],
    "weak_signal_mechanisms": [
      "fine_tuning (too generic, lacks structural content)",
      "adaptation (when only mentioning method name without mechanism)"
    ],
    "false_positive_causes": [
      "Generic ML methodology overlap (fine-tuning, training, optimization)",
      "Pattern descriptions containing only numbers or performance metrics",
      "Shared technical terms without shared structure"
    ]
  },

  "recommendations": {
    "filtering": [
      "Filter matches where pattern descriptions are just numbers (e.g., '0.919 without fine-tuning')",
      "Downweight 'fine_tuning' mechanism unless accompanied by specific structural details",
      "Require multi-word technical term overlap for high confidence (e.g., 'graph neural network', 'scaling law')"
    ],
    "extraction": [
      "Improve pattern extraction to capture more structure beyond keyword detection",
      "Extract cause-effect relationships, not just method names",
      "Avoid extracting patterns that are purely methodological without structural insight"
    ],
    "quality": [
      "50% precision at ≥0.7 similarity is consistent across sessions",
      "Top matches (≥0.9) are excellent quality",
      "Could improve to 70-80% precision by filtering weak mechanisms"
    ]
  }
}
