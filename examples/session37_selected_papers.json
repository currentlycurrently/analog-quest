{
  "total_selected": 69,
  "by_category": {
    "ecology": 7,
    "economics": 18,
    "physics": 20,
    "sociology": 4,
    "control": 0,
    "biology": 20
  },
  "expected_hit_rate": "60-80%",
  "expected_mechanisms": "41-55",
  "papers": [
    {
      "paper_id": 454,
      "arxiv_id": "2602.04150v1",
      "title": "A brief review of evolutionary game dynamics in the reinforcement learning paradigm",
      "abstract": "Cooperation, fairness, trust, and resource coordination are cornerstones of modern civilization, yet their emergence remains inadequately explained by the persistent discrepancies between theoretical predictions and behavioral experiments. Part of this gap may arise from the imitation learning paradigm commonly used in prior theoretical models, which assumes individuals merely copy successful neighbors according to predetermined, fixed rules. This review examines recent advances in evolutionary game dynamics that employ reinforcement learning (RL) as an alternative paradigm. In RL, individuals learn through trial and error and introspectively refine their strategies based on environmental feedback. We begin by introducing key concepts in evolutionary game theory and the two learning paradigms, then synthesize progress in applying RL to elucidate cooperation, trust, fairness, optimal resource coordination, and ecological dynamics. Collectively, these studies indicate that RL offers a promising unified framework for understanding the diverse social and ecological phenomena observed in human and natural systems.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 457,
      "arxiv_id": "2602.01492v1",
      "title": "From Discrete to Continuous Mixed Populations of Conformists, Nonconformists, and Imitators",
      "abstract": "In two-strategy decision-making problems, individuals often imitate the highest earners or choose either the common or rare strategy.\n  Individuals who benefit from the common strategy are conformists, whereas those who profit by choosing the less common one are called nonconformists.\n  The population proportions of the two strategies may undergo perpetual fluctuations\n  in finite, discrete, heterogeneous populations of imitators, conformists, and nonconformists.\n  How these fluctuations evolve as population size increases was left as an open question and is addressed in this paper.\n  We show that the family of Markov chains describing the discrete population dynamics forms a generalized stochastic approximation process for a differential inclusion--the continuous-time dynamics.\n  Furthermore, we prove that the continuous-time dynamics always equilibrate.\n  Then, by leveraging results from the stochastic approximation theory, we show that the amplitudes of fluctuations in the proportions of the two strategies in the population approach zero with probability one when the population size grows to infinity.\n  Our results suggest that large-scale perpetual fluctuations are unlikely in large, well-mixed populations consisting of these three types, particularly when imitators follow the highest earners.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 461,
      "arxiv_id": "2602.02553v1",
      "title": "Indirect Reciprocity with Environmental Feedback",
      "abstract": "Indirect reciprocity maintains cooperation in stranger societies by mapping individual behaviors onto reputation signals via social norms. Existing theoretical frameworks assume static environments with constant resources and fixed payoff structures. However, in real-world systems, individuals' strategic behaviors not only shape their reputation but also induce collective-level resource changes in ecological, economic, or other external environments, which in turn reshape the incentives governing future individual actions. To overcome this limitation, we establish a co-evolutionary framework that couples moral assessment, strategy updating, and environmental dynamics, allowing the payoff structure to dynamically adjust in response to the ecological consequences of collective actions. We find that this environmental feedback mechanism helps lower the threshold for the emergence of cooperation, enabling the system to spontaneously transition from a low-cooperation state to a stable high-cooperation regime, thereby reducing the dependence on specific initial conditions. Furthermore, while lenient norms demonstrate adaptability in static environments, norms with strict discrimination are shown to be crucial for curbing opportunism and maintaining evolutionary resilience in dynamic settings. Our results reveal the evolutionary dynamics of coupled systems involving reputation institutions and environmental constraints, offering a new theoretical perspective for understanding collective cooperation and social governance in complex environments.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 462,
      "arxiv_id": "2602.00193v1",
      "title": "Multi-strain SIS dynamics with coinfection under host population structure",
      "abstract": "Coinfection phenomena are common in nature, yet there is a lack of analytical approaches for coinfection systems with a high number of circulating and interacting strains. In this paper, we investigated a coinfection SIS framework applied to N strains, co-circulating in a structured host population. Adopting a general formulation for fixed host classes, defined by arbitrary epidemiological traits such as class-specific transmission rates, susceptibilities, clearance rates, etc., our model can be easily applied in different frameworks: for example, when different host species share the same pathogen, in classes of vaccinated or non-vaccinated hosts, or even in classes of hosts defined by the number of contacts. Using the strain similarity assumption, we identify the fast and slow variables of the epidemiological dynamics on the host population, linking neutral and non-neutral strain dynamics, and deriving a global replicator equation. This global replicator equation allows to explicitly predict coexistence dynamics from mutual invasibility coefficients among strains. The derived global pairwise invasion fitness matrix contains explicit traces of the underlying host population structure, and of its entanglement with the strain interaction and trait landscape. Our work thus enables a more comprehensive study and efficient simulation of multi-strain dynamics in endemic ecosystems, paving the way to deeper understanding of global persistence and selection forces, jointly shaped by pathogen and host diversity.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 463,
      "arxiv_id": "2601.22619v1",
      "title": "Epigenetic state inheritance drivers drug-tolerant persister-induced resistance in solid tumors: A stochastic agent-based model",
      "abstract": "The efficacy of anti-cancer therapies is severely limited by the emergence of drug resistance. While genetic drivers are well-characterized, growing evidence suggests that non-genetic mechanisms, particularly those involving drug-tolerant persisters (DTPs), play a pivotal role in solid tumor relapse. To elucidate the evolutionary dynamics of DTP-induced resistance, we develop a stochastic agent-based model (ABM) of solid tumor evolution that couples macroscopic population dynamics with microscopic epigenetic state inheritance during the cell cycle. Our simulations accurately reproduce the temporal progression of relapse observed in experimental studies, capturing the dynamic transition from sensitive cells to DTPs, and ultimately to stable resistant phenotypes under prolonged therapy. By explicitly modeling the epigenetic plasticity of individual cells, our model bridges the gap between cellular heterogeneity and population-level tumor evolution. Furthermore, we performed \\textit{in silico} clinical trials using virtual patient cohorts to evaluate therapeutic outcomes, demonstrating that optimized adaptive treatment strategies can significantly delay tumor relapse compared to standard dosing. This study provides a quantitative framework for dissecting DTP-driven resistance mechanisms and designing more effective, biologically informed therapeutic strategies.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 468,
      "arxiv_id": "2601.20981v1",
      "title": "Diversifying Toxicity Search in Large Language Models Through Speciation",
      "abstract": "Evolutionary prompt search is a practical black-box approach for red teaming large language models (LLMs), but existing methods often collapse onto a small family of high-performing prompts, limiting coverage of distinct failure modes. We present a speciated quality-diversity (QD) extension of ToxSearch that maintains multiple high-toxicity prompt niches in parallel rather than optimizing a single best prompt. ToxSearch-S introduces unsupervised prompt speciation via a search methodology that maintains capacity-limited species with exemplar leaders, a reserve pool for outliers and emerging niches, and species-aware parent selection that trades off within-niche exploitation and cross-niche exploration. ToxSearch-S is found to reach higher peak toxicity ($\\approx 0.73$ vs.\\ $\\approx 0.47$) and a extreme heavier tail (top-10 median $0.66$ vs.\\ $0.45$) than the baseline, while maintaining comparable performance on moderately toxic prompts. Speciation also yields broader semantic coverage under a topic-as-species analysis (higher effective topic diversity $N_1$ and larger unique topic coverage $K$). Finally, species formed are well-separated in embedding space (mean separation ratio $\\approx 1.93$) and exhibit distinct toxicity distributions, indicating that speciation partitions the adversarial space into behaviorally differentiated niches rather than superficial lexical variants. This suggests our approach uncovers a wider range of attack strategies.",
      "domain": "q-bio",
      "subdomain": "q-bio.PE",
      "category": "ecology"
    },
    {
      "paper_id": 530,
      "arxiv_id": "2601.05193v1",
      "title": "Cell size control in bacteria is modulated through extrinsic noise, single-cell- and population-growth",
      "abstract": "Living cells maintain size homeostasis by actively compensating for size fluctuations. Here, we present two stochastic maps that unify phenomenological models by integrating fluctuating single-cell growth rates and size-dependent noise mechanisms with cell size control. One map is applicable to mother machine lineages and the other to lineage trees of exponentially-growing cell populations, which reveals that population dynamics alter size control measured in mother machine experiments. For example, an adder can become more sizer-like or more timer-like at the population level depending on the noise statistics. Our analysis of bacterial data identifies extrinsic noise as the dominant mechanism of size variability, characterized by a quadratic conditional variance-mean relationship for division size across growth conditions. This finding contradicts the reported independence of added size relative to birth size but is consistent with the adder property in terms of the independence of the mean added size. Finally, we derive a trade-off between population-growth-rate gain and division-size noise. Correlations between size control quantifiers and single-cell growth rates inferred from data indicate that bacteria prioritize a narrow division-size distribution over growth rate maximisation.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "ecology"
    },
    {
      "paper_id": 83,
      "arxiv_id": "2602.03129v1",
      "title": "Mathematical Modeling of Common-Pool Resources: A Comprehensive Review of Bioeconomics, Strategic Interaction, and Complex Adaptive Systems",
      "abstract": "The governance of common-pool resources-resource systems characterized by high subtractability of yield and difficulty of exclusion-constitutes one of the most persistent and intricate challenges in the fields of economics, ecology, and applied mathematics. This comprehensive review delineates the historical and theoretical evolution of the mathematical frameworks developed to analyze, predict, and manage these systems. We trace the intellectual trajectory from the early, deterministic bioeconomic models of the mid-20th century, which established the fundamental tension between individual profit maximization and collective efficiency, to the contemporary era of complex coupled human-environment system models. Our analysis systematically dissects the formalization of the \"Tragedy of the Commons\" through the lens of classical cooperative and non-cooperative game theory, examining how the N-person Prisoner's Dilemma and Nash Equilibrium concepts provided the initial, albeit pessimistic, predictive baseline. We subsequently explore the \"Ostrom Turn,\" which necessitated the integration of institutional realism-specifically monitoring, graduated sanctions, and communication-into formal game-theoretic structures. The review further investigates the relaxation of rationality assumptions via evolutionary game theory and behavioral economics, highlighting the destabilizing roles of prospect theory and hyperbolic discounting. Finally, we synthesize recent advances in stochastic differential equations and agent-based computational economics, which capture the critical roles of spatial heterogeneity, noise-induced regime shifts, and early warning signals of collapse. By unifying these diverse mathematical threads, this review elucidates the shifting paradigm from static optimization to dynamic resilience in the management of the commons.",
      "domain": "econ",
      "subdomain": "econ.GN",
      "category": "economics"
    },
    {
      "paper_id": 191,
      "arxiv_id": "2601.04246v2",
      "title": "Technology Adoption and Network Externalities in Financial Systems: A Spatial-Network Approach",
      "abstract": "This paper develops a unified framework for analyzing technology adoption in financial networks that incorporates spatial spillovers, network externalities, and their interaction. The framework characterizes adoption dynamics through a master equation whose solution admits a Feynman-Kac representation as expected cumulative adoption pressure along stochastic paths through spatial-network space. From this representation, I derive the Adoption Amplification Factor -- a structural measure of technology leadership that captures the ratio of total system-wide adoption to initial adoption following a localized shock. A Levy jump-diffusion extension with state-dependent jump intensity captures critical mass dynamics: below threshold, adoption evolves through gradual diffusion; above threshold, cascade dynamics accelerate adoption through discrete jumps. Applying the framework to SWIFT gpi adoption among 17 Global Systemically Important Banks, I find strong support for the two-regime characterization. Network-central banks adopt significantly earlier ($\u03c1= -0.69$, $p = 0.002$), and pre-threshold adopters have significantly higher amplification factors than post-threshold adopters (11.81 versus 7.83, $p = 0.010$). Founding members, representing 29 percent of banks, account for 39 percent of total system amplification -- sufficient to trigger cascade dynamics. Controlling for firm size and network position, CEO age delays adoption by 11-15 days per year.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 199,
      "arxiv_id": "2512.21621v1",
      "title": "Mean-Field Price Formation on Trees with a Network of Relative Performance Concerns",
      "abstract": "Financial firms and institutional investors are routinely evaluated based on their performance relative to their peers. These relative performance concerns significantly influence risk-taking behavior and market dynamics. While the literature studying Nash equilibrium under such relative performance competitions is extensive, its effect on asset price formation remains largely unexplored. This paper investigates mean-field equilibrium price formation of a single risky stock in a discrete-time market where agents exhibit exponential utility and relative performance concerns. Unlike existing literature that typically treats asset prices as exogenous, we impose a market-clearing condition to determine the price dynamics endogenously within a relative performance equilibrium. Using a binomial tree framework, we establish the existence and uniqueness of the market-clearing mean-field equilibrium in both single- and multi-population settings. Finally, we provide illustrative numerical examples demonstrating the equilibrium price distributions and agents' optimal position sizes.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 88,
      "arxiv_id": "2602.02284v1",
      "title": "Optimal Solar Investment and Operation under Asymmetric Net Metering",
      "abstract": "We examine the joint investment and operational decisions of a prosumer, a customer who both consumes and generates electricity, under net energy metering (NEM) tariffs. Traditional NEM schemes provide temporally flat compensation at the retail price for net energy exports over a billing period. However, ongoing reforms in several U.S. states are introducing time-varying prices and asymmetric import/export compensation to better align incentives with grid costs. While prior studies treat PV capacity as exogenous and focus primarily on consumption behavior, this work endogenizes PV investment and derives the marginal value of solar capacity for a flexible prosumer under asymmetric NEM tariffs. We characterize optimal investment and show how optimal investment changes with prices and PV costs. Through this analysis, we identify a PV effect: changes in NEM pricing in one period can influence net demand and consumption in generating periods with unchanged prices through adjustments in optimal PV investment. The PV effect weakens the ability of higher import prices to increase prosumer payments, with direct implications for NEM reform. We validate our theoretical results in a case study using simulated household and tariff data derived from historical conditions in Massachusetts.",
      "domain": "econ",
      "subdomain": "econ.GN",
      "category": "economics"
    },
    {
      "paper_id": 97,
      "arxiv_id": "2602.00138v1",
      "title": "Regulatory Migration to Europe: ICO Reallocation Following U.S. Securities Enforcement",
      "abstract": "This paper examines whether a major U.S. regulatory clarification coincided with cross-border spillovers in crypto-asset entrepreneurial finance. We study the Securities and Exchange Commission's July 2017 DAO Report, which clarified the application of U.S. securities law to many initial coin offerings, and analyze how global issuance activity adjusted across regions. Using a comprehensive global dataset of ICOs from 2014 to 2021, we construct a region-month panel and evaluate issuance dynamics around the announcement. We document a substantial and persistent reallocation of ICO activity toward Europe following the DAO Report. In panel regressions with region and month fixed effects, Europe experiences an average post-2017 increase of approximately 14 additional ICOs per region-month relative to other regions, net of global market cycles. The results are consistent with cross-border regulatory spillovers in highly mobile digital-asset markets.",
      "domain": "econ",
      "subdomain": "econ.GN",
      "category": "economics"
    },
    {
      "paper_id": 98,
      "arxiv_id": "2601.20912v1",
      "title": "Clear Messages, Ambiguous Audiences: Measuring Interpretability in Political Communication",
      "abstract": "Text-based measurement in political research often treats classi6ication disagreement as random noise. We examine this assumption using con6idence-weighted human annotations of 5,000 social media messages by U.S. politicians. We 6ind that political communication is generally highly legible, with mean con6idence exceeding 0.99 across message type, partisan bias, and audience classi6ications. However, systematic variation concentrates in the constituency category, which exhibits a 1.79 percentage point penalty in audience classi6ication con6idence. Given the high baseline of agreement, this penalty represents a sharp relative increase in interpretive uncertainty. Within messages, intent remains clear while audience targeting becomes ambiguous. These patterns persist with politician 6ixed effects, suggesting that measurement error in political text is structured by strategic incentives rather than idiosyncratic coder error.",
      "domain": "econ",
      "subdomain": "econ.GN",
      "category": "economics"
    },
    {
      "paper_id": 176,
      "arxiv_id": "2602.02607v1",
      "title": "The Innovation Tax: Generative AI Adoption, Productivity Paradox, and Systemic Risk in the U.S. Banking Sector",
      "abstract": "This paper evaluates the causal impact of Generative Artificial Intelligence (GenAI) adoption on productivity and systemic risk in the U.S. banking sector. Using a novel dataset linking SEC 10-Q filings to Federal Reserve regulatory data for 809 financial institutions over 2018--2025, we employ two complementary identification strategies: Dynamic Spatial Durbin Models (DSDM) to capture network spillovers and Synthetic Difference-in-Differences (SDID) for causal inference using the November 2022 ChatGPT release as an exogenous shock. Our findings reveal a striking ``Productivity Paradox'': while DSDM estimates show that AI-adopting banks are high performers ($\u03b2> 0$), the causal SDID analysis documents a significant ``Implementation Tax'' -- adopting banks experience a 428-basis-point decline in ROE as they absorb GenAI integration costs. This tax falls disproportionately on smaller institutions, with bottom-quartile banks suffering a 517-basis-point ROE decline compared to 129 basis points for larger banks, suggesting that economies of scale provide significant advantages in AI implementation. Most critically, our DSDM analysis reveals significant positive spillovers ($\u03b8= 0.161$ for ROA, $p < 0.01$; $\u03b8= 0.679$ for ROE, $p < 0.05$), with spillovers among large banks reaching $\u03b8= 3.13$ for ROE, indicating that the U.S. banking system is becoming ``algorithmically coupled.'' This synchronization of AI-driven decision-making creates a new channel for systemic contagion: a technical failure in widely-adopted AI models could trigger correlated shocks across the entire financial network.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 181,
      "arxiv_id": "2602.00049v1",
      "title": "Exploring the Interpretability of Forecasting Models for Energy Balancing Market",
      "abstract": "The balancing market in the energy sector plays a critical role in physically and financially balancing the supply and demand. Modeling dynamics in the balancing market can provide valuable insights and prognosis for power grid stability and secure energy supply. While complex machine learning models can achieve high accuracy, their black-box nature severely limits the model interpretability. In this paper, we explore the trade-off between model accuracy and interpretability for the energy balancing market. Particularly, we take the example of forecasting manual frequency restoration reserve (mFRR) activation price in the balancing market using real market data from different energy price zones. We explore the interpretability of mFRR forecasting using two models: extreme gradient boosting (XGBoost) machine and explainable boosting machine (EBM). We also integrate the two models, and we benchmark all the models against a baseline naive model. Our results show that EBM provides forecasting accuracy comparable to XGBoost while yielding a considerable level of interpretability. Our analysis also underscores the challenge of accurately predicting the mFRR price for the instances when the activation price deviates significantly from the spot price. Importantly, EBM's interpretability features reveal insights into non-linear mFRR price drivers and regional market dynamics. Our study demonstrates that EBM is a viable and valuable interpretable alternative to complex black-box AI models in the forecast for the balancing market.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 190,
      "arxiv_id": "2601.03794v1",
      "title": "An Algorithmic Framework for Systematic Literature Reviews: A Case Study for Financial Narratives",
      "abstract": "This paper introduces an algorithmic framework for conducting systematic literature reviews (SLRs), designed to improve efficiency, reproducibility, and selection quality assessment in the literature review process. The proposed method integrates Natural Language Processing (NLP) techniques, clustering algorithms, and interpretability tools to automate and structure the selection and analysis of academic publications. The framework is applied to a case study focused on financial narratives, an emerging area in financial economics that examines how structured accounts of economic events, formed by the convergence of individual interpretations, influence market dynamics and asset prices. Drawing from the Scopus database of peer-reviewed literature, the review highlights research efforts to model financial narratives using various NLP techniques. Results reveal that while advances have been made, the conceptualization of financial narratives remains fragmented, often reduced to sentiment analysis, topic modeling, or their combination, without a unified theoretical framework. The findings underscore the value of more rigorous and dynamic narrative modeling approaches and demonstrate the effectiveness of the proposed algorithmic SLR methodology.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 194,
      "arxiv_id": "2601.06084v1",
      "title": "Who sets the range? Funding mechanics and 4h context in crypto markets",
      "abstract": "Financial markets often appear chaotic, yet ranges are rarely accidental. They emerge from structured interactions between market context and capital conditions. The four-hour timeframe provides a critical lens for observing this equilibrium zone where institutional positioning, leveraged exposure, and liquidity management converge. Funding mechanisms, especially in perpetual futures, act as disciplinary forces that regulate trader behavior, impose economic costs, and shape directional commitment. When funding aligns with the prevailing 4H context, price expansion becomes possible; when it diverges, compression and range-bound behavior dominate. Ranges therefore represent controlled balance rather than indecision, reflecting strategic positioning by informed participants. Understanding how 4H context and funding operate as market governors is essential for interpreting cryptocurrency price action as a rational, power-mediated process.",
      "domain": "q-fin",
      "subdomain": "q-fin.GN",
      "category": "economics"
    },
    {
      "paper_id": 810,
      "arxiv_id": "2602.05099v1",
      "title": "Personalized Policy Learning through Discrete Experimentation: Theory and Empirical Evidence",
      "abstract": "Randomized Controlled Trials (RCTs), or A/B testing, have become the gold standard for optimizing various operational policies on online platforms. However, RCTs on these platforms typically cover a limited number of discrete treatment levels, while the platforms increasingly face complex operational challenges involving optimizing continuous variables, such as pricing and incentive programs. The current industry practice involves discretizing these continuous decision variables into several treatment levels and selecting the optimal discrete treatment level. This approach, however, often leads to suboptimal decisions as it cannot accurately extrapolate performance for untested treatment levels and fails to account for heterogeneity in treatment effects across user characteristics. This study addresses these limitations by developing a theoretically solid and empirically verified framework to learn personalized continuous policies based on high-dimensional user characteristics, using observations from an RCT with only a discrete set of treatment levels. Specifically, we introduce a deep learning for policy targeting (DLPT) framework that includes both personalized policy value estimation and personalized policy learning. We prove that our policy value estimators are asymptotically unbiased and consistent, and the learned policy achieves a root-n-regret bound. We empirically validate our methods in collaboration with a leading social media platform to optimize incentive levels for content creation. Results demonstrate that our DLPT framework significantly outperforms existing benchmarks, achieving substantial improvements in both evaluating the value of policies for each user group and identifying the optimal personalized policy.",
      "domain": "econ",
      "subdomain": "econ.EM",
      "category": "economics"
    },
    {
      "paper_id": 811,
      "arxiv_id": "2602.04230v1",
      "title": "Validating Causal Message Passing Against Network-Aware Methods on Real Experiments",
      "abstract": "Estimating total treatment effects in the presence of network interference typically requires knowledge of the underlying interaction structure. However, in many practical settings, network data is either unavailable, incomplete, or measured with substantial error. We demonstrate that causal message passing, a methodology that leverages temporal structure in outcome data rather than network topology, can recover total treatment effects comparable to network-aware approaches. We apply causal message passing to two large-scale field experiments where a recently developed bipartite graph methodology, which requires network knowledge, serves as a benchmark. Despite having no access to the interaction network, causal message passing produces effect estimates that match the network-aware approach in direction across all metrics and in statistical significance for the primary decision metric. Our findings validate the premise of causal message passing: that temporal variation in outcomes can serve as an effective substitute for network observation when estimating spillover effects. This has important practical implications: practitioners facing settings where network data is costly to collect, proprietary, or unreliable can instead exploit the temporal dynamics of their experimental data.",
      "domain": "econ",
      "subdomain": "econ.EM",
      "category": "economics"
    },
    {
      "paper_id": 862,
      "arxiv_id": "2601.20452v1",
      "title": "Manipulation in Prediction Markets: An Agent-based Modeling Experiment",
      "abstract": "Prediction markets mobilize financial incentives to forecast binary event outcomes through the aggregation of dispersed beliefs and heterogeneous information. Their growing popularity and demonstrated predictive accuracy in political elections have raised speculation and concern regarding their susceptibility to manipulation and the potential consequences for democratic processes. Using agent-based simulations combined with an analytic characterization of price dynamics, we study how high-budget agents can introduce price distortions in prediction markets. We explore the persistence and stability of these distortions in the presence of herding or stubborn agents, and analyze how agent expertise affects market-price variance. Firstly we propose an agent-based model of a prediction market in which bettors with heterogeneous expertise, noisy private information, variable learning rates and budgets observe the evolution of public opinion on a binary election outcome to inform their betting strategies in the market. The model exhibits stability across a broad parameter space, with complex agent behaviors and price interactions producing self-regulatory price discovery. Second, using this simulation framework, we investigate the conditions under which a highly resourced minority, or ''whale'' agent, with a biased valuation can distort the market price, and for how long. We find that biased whales can temporarily shift prices, with the magnitude and duration of distortion increasing when non-whale bettors exhibit herding behavior and slow learning. Our theoretical analysis corroborates these results, showing that whales can shift prices proportionally to their share of market capital, with distortion duration depending on non-whale learning rates and herding intensity.",
      "domain": "q-fin",
      "subdomain": "q-fin.TR",
      "category": "economics"
    },
    {
      "paper_id": 864,
      "arxiv_id": "2601.18991v1",
      "title": "Who Restores the Peg? A Mean-Field Game Approach to Model Stablecoin Market Dynamics",
      "abstract": "USDC and USDT are the dominant stablecoins pegged to \\$1 with a total market capitalization of over \\$300B and rising. Stablecoins make dollar value globally accessible with secure transfer and settlement. Yet in practice, these stablecoins experience periods of stress and de-pegging from their \\$1 target, posing significant systemic risks. The behavior of market participants during these stress events and the collective actions that either restore or break the peg are not well understood. This paper addresses the question: who restores the peg? We develop a dynamic, agent-based mean-field game framework for fiat-collateralized stablecoins, in which a large population of arbitrageurs and retail traders strategically interacts across explicit primary (mint/redeem) and secondary (exchange) markets during a de-peg episode. The key advantage of this equilibrium formulation is that it endogenously maps market frictions into a market-clearing price path and implied net order flows, allowing us to attribute peg-reverting pressure by channel and to stress-test when a given mechanism becomes insufficient for recovery. Using three historical de-peg events, we show that the calibrated equilibrium reproduces observed recovery half-lives and yields an order flow decomposition in which system-wide stress is predominantly stabilized by primary-market arbitrage, whereas episodes with impaired primary redemption require a joint recovery via both primary and secondary markets. Finally, a quantitative sensitivity analysis of primary-rail frictions identifies a non-linear breakdown threshold. Beyond this point, secondary-market liquidity acts mainly as a second-order amplifier around this primary-market bottleneck.",
      "domain": "q-fin",
      "subdomain": "q-fin.TR",
      "category": "economics"
    },
    {
      "paper_id": 949,
      "arxiv_id": "2602.03720v1",
      "title": "Nested search",
      "abstract": "I introduce and study a nested search problem modeled as a tree structure that generalizes Weitzman (1979) in two ways: (1) search progresses incrementally, reflecting real-life scenarios where agents gradually acquire information about the prizes; and (2) the realization of prizes can be correlated, capturing similarities among them. I derive the optimal policy, which takes the form of an index solution. I apply this result to study monopolistic competition in a market with two stages of product inspection. My application illustrates that regulations on drip pricing lower equilibrium price and raise consumer surplus.",
      "domain": "econ",
      "subdomain": "econ.TH",
      "category": "economics"
    },
    {
      "paper_id": 952,
      "arxiv_id": "2602.02833v1",
      "title": "Endogenous Product Design: A Linear Demand Approach",
      "abstract": "This paper develops a linear-demand framework to investigate endogenous product design. The key assumption is that the same product characteristics which drive goods utility also (at least partially) shape competitive interactions across products. I model this relationship allowing for differences in each characteristic's relevance to competition, their absolute intensity per good, and correlations to other characteristics. The framework is novel in its broad applicability to settings with any finite number of goods, firms, and attributes, allowing for both vertical and horizontal differentiation, all in an empirically testable model. Under Bertrand price competition I show that across different market structures, a pattern emerges: product differentiation along product attributes that firms control is primarily vertical, with horizontal differentiation only in latent attributes. Counter to standard intuition, simulations show that allowing for endogenous design can imply higher consumer surplus under monopoly than under competition, as monopoly's stronger incentives for attribute investment translate into higher effective quality.",
      "domain": "econ",
      "subdomain": "econ.TH",
      "category": "economics"
    },
    {
      "paper_id": 954,
      "arxiv_id": "2602.01958v1",
      "title": "\"Sail Fast, Then Wait\" in First-come, First-served Port Queues: Information Sharing for Sustainable Shipping",
      "abstract": "This study develops a novel class of queueing game to explain a common practice in cargo shipping \"Sail Fast, Then Wait\" (SFTW), and demonstrates that resolving information asymmetry among ships can deconcentrate port arrival times. We formulate a competitive navigating environment as an incomplete information game where players strategically decide their arrival time within heterogeneous feasible sets under First-Come, First-Served port policy. Our results show that in incomplete information settings, SFTW emerges as the unique symmetric equilibrium. Conversely, under complete information, the set of equilibria expands, allowing for slower and more environmentally friendly actions without compromising service order. We further quantitatively evaluate the effect of information enrichment based on empirical data. Our findings suggest that the prevalence of technologies enabling ships to infer others' private information can effectively reduce SFTW and enable more energy-efficient and environmentally sustainable operations.",
      "domain": "econ",
      "subdomain": "econ.TH",
      "category": "economics"
    },
    {
      "paper_id": 955,
      "arxiv_id": "2602.01790v1",
      "title": "Beyond Hurwicz: Incentive Compatibility under Informational Decentralization",
      "abstract": "Achieving incentive compatibility under informational decentralization is impossible within the class of direct and revelation-equivalent mechanisms typically studied in economics and computer science. We show that these impossibility results are conditional by identifying a narrow class of non-revelation-equivalent mechanisms that sustain enforcement by inferring preferences indirectly through parallel, uncorrelatable games.",
      "domain": "econ",
      "subdomain": "econ.TH",
      "category": "economics"
    },
    {
      "paper_id": 1316,
      "arxiv_id": "2602.05212v1",
      "title": "Mean-field behavior of the finite size Ising model near its critical point",
      "abstract": "Universality classes encompass the analogous thermodynamic behavior of unlike physical systems, at different spatial dimensions $d$, in the vicinity of their critical point. Critical exponents define these classes, with the Ising model being the outstanding prototype that elucidates the differences from the mean-field category, believed to be valid above a critical dimension only. Here, in apparent striking contradiction to the Ising universality class, we demonstrate that the critical behavior of a finite Ising system of $N$ spins in $d = 3$ obeys mean-field Landau theory in the vicinity of its critical point, with classical critical exponents. Yet, when expressed in terms of the linear size $L$ of the system, the free energy unveils its proper finite-size scaling form, from which the thermodynamic limit critical temperature $T_c$ and the Ising critical exponents $\u03bd$, $\u03b3$ and $\u03b2$ can be identified. We find that the larger the size $L$, the smaller the mean-field region, shrinking to zero in the thermodynamic limit. These conclusions are achieved via the use of an alternative approach to collect data from a Monte Carlo simulation of a three-dimensional Ising model that allows for the evaluation of the free energy per spin $f = f(T,m;L)$ and of the coexistence curve, or spontaneous magnetization at zero magnetic field, $m_{\\rm coex} = m(T;L)$ as functions of temperature $T$ and magnetization per spin $m = M/N$. Our results suggest a revision of the role of mean-field theory in the elucidation of critical phenomena.",
      "domain": "cond-mat",
      "subdomain": "cond-mat.stat-mech",
      "category": "physics"
    },
    {
      "paper_id": 152,
      "arxiv_id": "2602.04999v1",
      "title": "Metastability and ripening of multi-component liquid mixtures",
      "abstract": "Understanding how multi-component liquid mixtures undergo phase separation is central to elucidating biophysical organization in the cell. Here, combining analytical and numerical results, we characterise the dynamics of mixtures with disordered interactions among the components. We first study how two coexisting phases become unstable, leading to multiphase coexistence. We then show that the scaling of droplet radius as $t^{1/3}$ and droplet number as $n^{-2/3}$, characteristic of Ostwald ripening in two dimensions, can be severely delayed. This delay arises from glass-like relaxation and the emergence of long-lived metastable states characterized by different wetting angles.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 165,
      "arxiv_id": "2601.22967v1",
      "title": "How adaptation to food resources and death rates shape oscillatory dynamics in a microbial population",
      "abstract": "Microbes constantly interact with their environment by depleting and transforming food sources. Theoretical studies have mainly focused on Lotka-Volterra models, which do not account for food source dynamics. In contrast, consumer-resource models, which consider food source dynamics, are less explored. In particular, it is still unclear what physical mechanisms control oscillatory dynamics at a single population level, a phenomenon which can only be captured by a consumer-resource model. Here, we present a minimalistic consumer-resource model of a single microbial population with growth and death dynamics, consuming a continuously replenishing substrate. Our model reveals that decaying oscillations can occur around steady state if and only if the timescale of microbial adaptation to food supply changes exceeds the death timescale. This interplay of timescales allows us to rationalize the emergence of oscillatory dynamics when adding various biophysical ingredients to the model. We find that microbial necromass recycling or complementary use of multiple food sources reduces the parameter range for oscillations and increases the decay rate of oscillations. Requiring multiple simultaneous food sources has the opposite effect. Essentially, facilitating growth reduces the likelihood of oscillations around a fixed point. We further demonstrate that such damped oscillatory behavior is correlated with persistent oscillatory behavior in a noisy environment. We hope our work will motivate further investigations of consumer-resource models to improve descriptions of environments where food source distributions vary in space and time.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 354,
      "arxiv_id": "2602.03738v1",
      "title": "Emergent structures in coupled opinion and network dynamics",
      "abstract": "This paper investigates a model of opinion formation on an adaptive social network, consisting of a system of coupled ordinary differential equations for individuals' opinions and corresponding network edge weights. A key driver of the system's behaviour is the form of the interaction function, which determines the strength of interactions based on the distance between individuals' opinions and appears in both opinion and network dynamics. Two cases are examined: in the first the interaction function is always positive and in the second case the interaction function is of bounded-confidence type. In both cases there is positive feedback between opinion clustering and the emergence of community structure in the social network. This is confirmed through analytical results on long-term behaviour, extending existing results for a fixed network, as well as through numerical simulations. Transient network dynamics are also examined through a short-time approximation that captures the `typical' early network dynamics. Each approach improves some aspect of our understanding of the interplay between opinion and network evolution.",
      "domain": "physics",
      "subdomain": "physics.soc-ph",
      "category": "physics"
    },
    {
      "paper_id": 544,
      "arxiv_id": "2602.05918v1",
      "title": "Photonic neuromorphic processing with coupled spiking silicon microrings",
      "abstract": "Understanding the physical computing mechanisms of individual network nodes is essential for scaling neuromorphic photonic architectures. This work proposes a compact passive nonlinear photonic core based on a Side-Coupled Integrated Spaced Sequence of Resonators (SCISSOR) made of three nominally equal microrings and investigate its computing capabilities. Its nonlinearities and internal feedback enable analogue, spiking, and bistable responses that are accessed by tuning the injection power and wavelength. Implemented as a single nonlinear node in a time-multiplexed reservoir computing, the SCISSOR achieves error-free classification on the Iris dataset and accuracies above 97% on the Sonar task, using both analogue and digital reservoir representations with 150 virtual nodes. In the digital scheme, spiking dynamics naturally generate sparse reservoir states, enabling efficient classification even with a single spike. Intriguingly, optimal operating points are at the boundaries where sharp transitions in dynamical complexity and/or output power occur. In these points, the SCISSOR supports high task-performance, opening novel strategies for future on-chip training. Spiking and thermal bistabilities also participate to enhance the computational performance at low injected powers below 4 mW. These results suggest optical coupled microring resonators as effective building blocks for future edge computing and neuromorphic photonic systems.",
      "domain": "physics",
      "subdomain": "physics.optics",
      "category": "physics"
    },
    {
      "paper_id": 928,
      "arxiv_id": "2601.21510v1",
      "title": "From Basins to safe sets: a machine learning perspective on chaotic dynamics",
      "abstract": "The study of chaos has long relied on computationally intensive methods to quantify unpredictability and design control strategies. Recent advances in machine learning, from convolutional neural networks to transformer architectures, provide new ways to analyze complex phase space structures and enable real time action in chaotic dynamics. In this perspective article, we highlight how data driven approaches can accelerate classical tasks such as estimating basin characterization metrics, or partial control of transient chaos, while opening new possibilities for scalable and robust interventions in chaotic systems. In recent studies, convolutional networks have reproduced classical basin metrics with negligible bias and low computational cost, while transformer based surrogates have computed accurate safety functions within seconds, bypassing the recursive procedures required by traditional methods. We discuss current opportunities, remaining challenges, and future directions at the intersection of nonlinear dynamics and artificial intelligence.",
      "domain": "nlin",
      "subdomain": "nlin.CD",
      "category": "physics"
    },
    {
      "paper_id": 1276,
      "arxiv_id": "2602.04171v1",
      "title": "A universal waveguide mass--energy relation for lossy one-dimensional waves in nature",
      "abstract": "Finite, lossy waveguides are ubiquitous: distributed attenuation with partial reflections produces feedback, resonance, delays and decay across electromagnetic, acoustic, photonic, quantum-transport and electrochemical interfaces. Yet standard impedance/scattering tools and weak-loss resonator approximations do not provide low-dimensional invariants that remain predictive under intrinsic asymmetry and realistic boundaries, nor do they cleanly separate total absorption from useful power delivered to a load. Here we develop a unified mass--energy framework for linear, single-mode, one-dimensional systems, in which energy-like and power-flow variables $(\\mathcal{U},\\mathcal{S})$ satisfy the universal invariant $\\mathcal{U}^2-\\mathcal{S}^2=|\u0393_g|^2$, with the effective standing-wave ``mass'' $|\u0393_g|$ becoming state-dependent under asymmetry. The Cai--Smith chart gives a bounded state-space map of stability, feedback proximity and operating states, and makes explicit the divergence between maximum absorption and useful delivery under loss. We derive four laws governing absorption and emission, validate the invariant in multiport optics via coherent perfect absorption at exceptional points using a basis-independent SVD criterion (reconciling quadratic vs quartic near-zero scaling), and map electrochemical polarization onto the same geometry by extracting $|\u0393_g|$ from two-mode orthogonal fits to reveal a universal storage-to-transfer transition across pH. This framework provides a transferable design language for dissipative, boundary-controlled systems.",
      "domain": "physics",
      "subdomain": "physics.app-ph",
      "category": "physics"
    },
    {
      "paper_id": 1295,
      "arxiv_id": "2602.04969v1",
      "title": "Taming multiparty entanglement at measurement-induced phase transitions",
      "abstract": "Measurement-induced phase transitions (MIPT) give rise to novel dynamical states of quantum matter realized by balancing unitary evolution and measurements. We present large-scale numerical simulations of a trapped-ion native MIPT, argued to belong to the universality class described by the Haar non-unitary conformal field theory. First, through a finite-size analysis we obtained the critical measurement rate, and correlation length exponent, which falls close to the percolation value. Second, by leveraging a monotone computable via semi-definite programming, we uncover robust algebraic decay of genuine multiparty entanglement (GME) versus separation for 2, 3, and 4 parties. The corresponding critical exponents are lower-bounded by those of the multiparty mutual information, which we determine up to 4 parties, and conjecture to be (k+2) for k parties. Additionally, we derive lower bounds for both GME and multiparty mutual information.",
      "domain": "cond-mat",
      "subdomain": "cond-mat.str-el",
      "category": "physics"
    },
    {
      "paper_id": 1336,
      "arxiv_id": "2602.01972v1",
      "title": "Heat load measurements for the PIP-II pHB650 cryomodule",
      "abstract": "Phase-3 testing of the pHB650 cryomodule at the PIP-II Injector Test Facility was conducted to evaluate the effectiveness of heat load mitigations performed after earlier phases of testing and to continue pinpointing any sources of unexpectedly high heat loads.. The programme measured HTTS, LTTS, and 2 K isothermal/non-isothermal loads under \"standard\", \"linac\", and \"simulated dynamic\" operating modes, recording data both inside the cryomodule and across the bayonet can circuits. Thermal-acoustic oscillations were eliminated by replacing the original G10 cooldown-valve stem with a stainless-steel stem fitted with wipers. A newly developed Python script automated acquisition of ACNET data, performed real-time heat-load calculations, and generated plots and tables that were posted to the electronic logbook within minutes, vastly reducing manual effort and accelerating feedback between SRF and cryogenics teams. Analysis showed that JT heat-exchanger effectiveness and temperature stratification in the two-phase and relief piping strongly influence the observed loads and helped isolate sources of excess heat. The campaign demonstrates that rigorous pre-test planning, real-time diagnostics, and automated reporting can improve both accuracy and efficiency, providing a template for future PIP-II cryomodule tests and for implementing targeted heat-load mitigations.",
      "domain": "physics",
      "subdomain": "physics.acc-ph",
      "category": "physics"
    },
    {
      "paper_id": 1434,
      "arxiv_id": "2602.00962v1",
      "title": "Critical Temperatures from Domain-Wall Microstate Counting: A Topological Solution for the Potts Universality Class",
      "abstract": "We derive a universal relation for the critical temperatures of the $q$-state Potts model based on the counting of domain-wall microstates. By balancing interface energy against configurational entropy, we show that the critical temperature is determined by the ratio of the coordination-dependent energy cost to the logarithm of a total multiplicity factor. This factor decomposes into a lattice-topological constant, representing a projection from an underlying orthogonal Euclidean space, and a term representing Markovian sampling in the $q$-dimensional state space. The framework recovers exact solutions for two-dimensional square, triangular, and honeycomb lattices and achieves sub-3\\% accuracy for three-dimensional simple cubic, bcc, fcc, and diamond geometries. This approach unifies the Potts universality class into a single geometric classification, revealing that the phase transition is governed by the saturation of interface propagation through the lattice manifold and providing a predictive tool that characterizes the entire $q$-state family from a single topological calibration.",
      "domain": "cond-mat",
      "subdomain": "cond-mat.stat-mech",
      "category": "physics"
    },
    {
      "paper_id": 1864,
      "arxiv_id": "2602.00658v1",
      "title": "An Oscillation-Free Real Fluid Quasi-Conservative Finite Volume Method for Transcritical and Phase-Change Flows",
      "abstract": "A new Real Fluid Quasi-Conservative (RFQC) finite volume method is developed to address the numerical simulation of real fluids involving shock waves in transcritical and phase-change flows. To eliminate the spurious pressure oscillations inherent in fully conservative schemes, we extend the classic five-equation quasi-conservative model, originally designed for two-phase flows, to real fluids governed by arbitrary equations of state (EoS). The RFQC method locally linearizes the real fluid EoS at each grid point and time step, constructing and evolving the frozen Gr\u00fcneisen coefficient $\u0393$ and the linearization remainder $E_0$ via two advection equations. At the end of each time step, the evolved $\u0393$ and $E_0$ are utilized to reconstruct the oscillation-free pressure field, followed by a thermodynamic re-projection applied to the conserved variables. Theoretical analysis demonstrates that, in smooth regions, the energy conservation error of the RFQC method is a high-order term relative to the spatial reconstruction truncation error. In discontinuous regions, this error is determined by the entropy increase rate, thereby maintaining consistency with the inherent truncation error of shock-capturing methods. A series of numerical tests verifies that the method can robustly simulate complex flow processes with only minor energy conservation errors, including transcritical flows, phase transitions, and shock-interface interactions. The RFQC method is proven to be both accurate and robust in capturing shock waves and phase transitions.",
      "domain": "physics",
      "subdomain": "physics.comp-ph",
      "category": "physics"
    },
    {
      "paper_id": 153,
      "arxiv_id": "2602.04905v1",
      "title": "Heterogeneity dominates irreversibility in random Markov models",
      "abstract": "We introduce a two-parameter ensemble of random discrete-time Markov models that simultaneously captures critical slowing down and broken detailed balance. Extending a previously studied heterogeneous Markov ensemble, we incorporate correlations between forward and backward transition rates through a single asymmetry parameter $\u03b3$, while heterogeneity is controlled by $\u03b5$. Using results from random matrix theory, we identify a critical locus $\u03b5_c(\u03b3,N)$ at which relaxation times diverge and spectral universality breaks down. We characterize the behavior of entropy production, predictive information, and relaxation dynamics across the ensemble, showing that many observables depend strongly on heterogeneity but only weakly on asymmetry, except near the symmetric limit. Applying maximum-likelihood inference to human fMRI and EEG data, we find that both modalities operate near the predicted critical locus and occupy a similar region of the $\u03b5-\u03b3$ plane, supporting a super-universality of human brain dynamics. While ensemble averages are well captured by the null model, empirical data exhibit substantially enhanced variability, indicating subject-specific structure beyond random expectations. Our results unify criticality and nonequilibrium measures within a single framework and clarify their intertwined role in the analysis of complex biological dynamics.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 155,
      "arxiv_id": "2602.02868v1",
      "title": "Quantum Information Flow in Microtubule Tryptophan Networks",
      "abstract": "Networks of aromatic amino acid residues within microtubules, particularly those formed by tryptophan, may serve as pathways for optical information flow. Ultraviolet excitation dynamics in these networks are typically modeled with effective non-Hermitian Hamiltonians. By extending this approach to a Lindblad master equation that incorporates explicit site geometries and dipole orientations, we track how correlations are generated, routed, and dissipated, while capturing both energy dissipation and information propagation among coupled chromophores. We compare localized injections, fully delocalized preparations, and eigenmode-based initial states. To quantify the emerging quantum-informational structure, we evaluate the $L_1$ norm of coherence, the correlated coherence, and the logarithmic negativity within and between selected chromophore sub-networks. The results reveal a strong dependence of both the direction and persistence of information flow on the type of initial preparation. Superradiant components drive the rapid export of correlations to the environment, whereas subradiant components retain them and slow their leakage. Embedding single tubulin units into larger dimers and spirals reshapes pairwise correlation maps and enables site-selective routing. Scaling to larger ordered lattices strengthens both export and retention channels, whereas static energetic and structural disorder suppresses long-range transport and reduces overall correlation transfer. These findings provide a Lindbladian picture of information flow in cytoskeletal chromophore networks and identify structural and dynamical conditions that transiently preserve nonclassical correlations in microtubules.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 157,
      "arxiv_id": "2602.01758v1",
      "title": "Short-wave admittance correction for a time-domain cochlear transmission line model",
      "abstract": "Transmission line (TL) models implemented in the time domain can efficiently simulate basilar-membrane (BM) displacement in response to transient or non-stationary sounds. By design, a TL model is well-suited for an one-dimensional (1-D) characterization of the traveling wave, but the real configuration of the cochlea also introduces higher-dimensional effects. Such effects include the focusing of the pressure around the BM and transverse viscous damping, both of which are magnified in the short-wave region. The two effects depend on the wavelength and are more readily expressed in the frequency domain. In this paper, we introduce a numerical correction for the BM admittance to account for 2-D effects in the time domain using autoregressive filtering and regression techniques. The correction was required for the implementation of a TL model tailored to the gerbil cochlear physiology. The model, which includes instantaneous nonlinearities in the form of variable damping, initially presented insufficient compression with increasing sound levels. This limitation was explained by the strong coupling between gain and frequency selectivity assumed in the 1-D nonlinear TL model, whereas cochlear frequency selectivity shows only a moderate dependence on sound level in small mammals. The correction factor was implemented in the gerbil model and made level-dependent using a feedback loop. The updated model achieved some decoupling between frequency selectivity and gain, providing 5 dB of additional gain and extending the range of sound levels of the compressive regime by 10 dB. We discuss the relevance of this work through two key features: the integration of both analytical and regression methods for characterizing BM admittance, and the combination of instantaneous and non-instantaneous nonlinearities.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 160,
      "arxiv_id": "2602.00832v1",
      "title": "Size and shape of terrestrial animals",
      "abstract": "Natural selection for terrestrial locomotion has yielded unifying patterns in the body shape of legged animals, often manifesting as scaling laws. One such pattern appears in the frontal aspect ratio. Smaller animals like insects typically adopt a landscape frontal aspect ratio, with a wider side-to-side base of support than center of mass height. Larger animals like elephants, however, are taller than wide with a portrait aspect ratio. Known explanations for postural scaling are restricted to animal groups with similar anatomical and behavioural motifs, but the trend in frontal aspect ratio transcends such commonalities. Here we show that vertebrates and invertebrates with diverse body plans, ranging in mass from 28 mg to 22000 kg, exhibit size-dependent scaling of the frontal aspect ratio driven by the need for lateral stability on uneven natural terrain. Because natural terrain exhibit scale-dependent unevenness, and the frontal aspect ratio is important for lateral stability during locomotion, smaller animals need a wider aspect ratio for stability. This prediction is based on the fractal property of natural terrain unevenness, requires no anatomical or behavioural parameters, and agrees with the measured scaling despite vast anatomical and behavioural differences. Furthermore, a statistical phylogenetic comparative analysis found that shared ancestry and random trait evolution cannot explain the measured scaling. Thus, our findings reveal that terrain roughness, acting through natural selection for stability, likely drove the macroevolution of frontal shape in terrestrial animals.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 166,
      "arxiv_id": "2602.00200v1",
      "title": "Intelligent Control of Transportation Flow in Physarum Networks",
      "abstract": "The Physarum network expands or retracts in response to environmental stimuli, demonstrating an intelligent adaptive capability to locate optimal paths for nutrient transport. The underlying physical mechanism governing this intelligence behavior remains an unresolved problem in biological physics.unlike the unidirectional flow typical of urban traffic networks, cytoplasmic flow within the Physarum network exhibits periodic oscillations modulated by biological repellents and attractants. In this study, we investigate how local flows within the networks branch channels interact to collectively govern the global oscillatory dynamics.We find that the measured flow fluxes at intersection nodes obey Kirchhoff's current law. Phase differences exist among the flows in different branches.At the microscopic scale, flow distribution exhibits only brief periods of traffic congestion, which are resolved by the oscillatory flows. By mapping the flow flux vectors onto the magnetic moment vector of spin ice model, we demonstrate that the flow vectors strictly obey the ice-rule of vertex models in statistical physics.Notably, the three branches converging at a Y-shaped node never become blocked simultaneously, thereby preventing traffic congestion and ensuring efficient transmission of nutrients and signals.This intelligent flow control phenomenon offers novel insights for addressing traffic congestion and advances our understanding of frustrated quantum magnetism.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 168,
      "arxiv_id": "2601.22564v1",
      "title": "Cross-feeding yields high-dimensional chaos and coexistence of species beyond exclusion principle",
      "abstract": "Species interactions through cross-feeding via leakage and uptake of chemicals are important in microbial communities, and play an essential role in the coexistence of diverse species. Here, we study a simple dynamical model of a microbial community in which species interact by competing for the uptake of common metabolites that are leaked by other species. The model includes coupled dynamics of species populations and chemical concentrations in the medium, allowing for a variety of uptake and leakage networks among species. Depending on the structure of these networks, the system exhibits different attractors, including fixed points, limit cycles, low-dimensional chaos, and high-dimensional chaos. In the fixed-point and limit-cycle cases, the number of coexisting species is bounded by the number of exchangeable chemicals, consistent with the well-known competitive exclusion principle. In contrast, in the low-dimensional chaotic regime, the number of coexisting species exhibits noticeable but limited excess over this limit. Remarkably, in the high-dimensional chaotic regime, a much larger number of species beyond this limit coexist persistently over time. In this case, the rank-abundance distribution is broader than exponential, as often observed in real ecosystems. The population dynamics displays intermittent switching among quasi-stationary states, while the chemical dynamics explore most of the high dimensions. We find that such high-dimensional chaos is ubiquitous when the number of uptake chemicals is moderately larger than the number of leaked chemicals. Our results identify high-dimensional chaos with intermittent switching as a generic dynamical mechanism that stabilizes coexistence in interacting systems. We discuss its relevance to sustaining diverse microbial communities with leak-uptake cross-feeding.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 169,
      "arxiv_id": "2601.22293v1",
      "title": "Distinguishable spreading dynamics in microbial communities",
      "abstract": "A packed community of exponentially proliferating microbes will spread in size exponentially. However, due to nutrient depletion, mechanical constraints, or other limitations, exponential proliferation is not indefinite, and the spreading slows. Here, we theoretically explore a fundamental question: is it possible to infer the dominant limitation type from the spreading dynamics? Using a continuum active fluid model, we consider three limitations to cell proliferation: intrinsic growth arrest (e.g., due to sporulation), pressure from other cells, and nutrient access. We find that memoryless growth arrest still results in superlinear (accelerating) spreading, but at a reduced rate. In contrast, pressure-limited growth results in linear (constant-speed) spreading in the long-time limit. We characterize how the expansion speed depends on the maximum growth rate, the limiting pressure value, and the effective fluid friction. Interestingly, nutrient-limited growth results in a phase transition: depending on the nutrient supply and how efficiently nutrient is converted to biomass, the spreading can be either superlinear or sublinear (decelerating). We predict the phase boundary in terms of these parameters and confirm with simulations. Thus, our results suggest that when an expansion slowdown is observed, its dominant cause is likely nutrient depletion. More generally, our work suggests that cell-level growth limitations can be inferred from population-level dynamics, and it offers a methodology for connecting these two scales.",
      "domain": "physics",
      "subdomain": "physics.bio-ph",
      "category": "physics"
    },
    {
      "paper_id": 200,
      "arxiv_id": "2602.05911v1",
      "title": "Platform and Framework for Time-Resolved Nanoscale Thermal Transport Measurements in STEM",
      "abstract": "Understanding heat transport at the nanometer scale is critical for semiconductor devices, quantum materials, and thermal management of nanostructures, yet direct local measurements of thermal conductivity and heat capacity remain scarce. We developed a laser-excitation system integrated into a scanning transmission electron microscope (STEM) for nanoscale thermal transport measurements using ultra-high-resolution electron energy-loss spectroscopy (EELS). A fiber-coupled laser is introduced via a modified aperture mechanism, enabling flexible holder geometries and large tilt angles without optical elements in the polepiece gap. Synchronization of pulsed laser excitation with an externally gated direct electron detector provides temporal resolution about 50 ns at <10 meV energy resolution. Local temperatures are determined via the principle of detailed balance, and thermal transport parameters are extracted by fitting a forward-time central-space heat diffusion model including radiative losses. For amorphous carbon films, we obtain a thermal conductivity of 1.24 $\\frac{W}{m\\cdot K}$ and a heat capacity of 821 $\\frac{J}{kg\\cdot K}$, consistent with literature. This framework enables time-resolved nanoscale measurements of thermal transport in materials and devices.",
      "domain": "cond-mat",
      "subdomain": "cond-mat.mtrl-sci",
      "category": "physics"
    },
    {
      "paper_id": 352,
      "arxiv_id": "2602.04481v1",
      "title": "The impact of heterogeneity on the co-evolution of cooperation and epidemic spreading in complex networks",
      "abstract": "The dynamics of herd immunity depend crucially on the interaction between collective social behavior and disease transmission, but the role of heterogeneity in this context frequently remains unclear. Here, we dissect this co-evolutionary feedback by coupling a public goods game with an epidemic model on complex networks, including multiplex and real-world networks. Our results reveals a dichotomy in how heterogeneity shapes outcomes. We demonstrate that structural heterogeneity in social networks acts as a powerful catalyst for cooperation and disease suppression. This emergent effect is driven by highly connected hubs who, facing amplified personal risk, adopt protective strategies out of self-interest. In contrast, heterogeneity in individual infection costs proves detrimental, undermining cooperation and amplifying the epidemic. This creates a ``weakest link'' problem, where individuals with low perceived risk act as persistent free-riders and disease reservoirs, degrading the collective response. Our findings establish that heterogeneity is a double-edged sword: its impact is determined by whether it creates an asymmetry of influence (leverage points) or an asymmetry of motivation (weakest links), recommending disease intervention policies that facilitate cooperative transition in hubs (strengthening the leverage point) and homogenize incentives to weakest links.",
      "domain": "physics",
      "subdomain": "physics.soc-ph",
      "category": "physics"
    },
    {
      "paper_id": 1948,
      "arxiv_id": "2602.02625v1",
      "title": "OpenClaw Agents on Moltbook: Risky Instruction Sharing and Norm Enforcement in an Agent-Only Social Network",
      "abstract": "Agentic AI systems increasingly operate in shared social environments where they exchange information, instructions, and behavioral cues. However, little empirical evidence exists on how such agents regulate one another in the absence of human participants or centralized moderation. In this work, we present an empirical analysis of OpenClaw agents interacting on Moltbook, an agent-only social network. Analyzing 39,026 posts and 5,712 comments produced by 14,490 agents, we quantify the prevalence of action-inducing instruction sharing using a lexicon-based Action-Inducing Risk Score (AIRS), and examine how other agents respond to such content. We find that 18.4% of posts contain action-inducing language, indicating that instruction sharing is a routine behavior in this environment. While most social responses are neutral, posts containing actionable instructions are significantly more likely to elicit norm-enforcing replies that caution against unsafe or risky behavior, compared to non-instructional posts. Importantly, toxic responses remain rare across both conditions. These results suggest that OpenClaw agents exhibit selective social regulation, whereby potentially risky instructions are more likely to be challenged than neutral content, despite the absence of human oversight. Our findings provide early empirical evidence of emergent normative behavior in agent-only social systems and highlight the importance of studying social dynamics alongside technical safeguards in agentic AI ecosystems.",
      "domain": "cs",
      "subdomain": "cs.SI",
      "category": "sociology"
    },
    {
      "paper_id": 634,
      "arxiv_id": "2602.05109v1",
      "title": "Blockchain Technology for Public Services: A Polycentric Governance Synthesis",
      "abstract": "National governments are increasingly adopting blockchain to enhance transparency, trust, and efficiency in public service delivery. However, evidence on how these technologies are governed across national contexts remains fragmented and overly focused on technical features. Using Polycentric Governance Theory, this study conducts a systematic review of peer-reviewed research published between 2021 and 2025 to examine blockchain-enabled public services and the institutional, organizational, and information-management factors shaping their adoption. Following PRISMA guidelines, we synthesize findings from major digital government and information systems databases to identify key application domains, including digital identity, electronic voting, procurement, and social services, and analyze the governance arrangements underpinning these initiatives. Our analysis reveals that blockchain adoption is embedded within polycentric environments characterized by distributed authority, inter-organizational coordination, and layered accountability. Rather than adopting full decentralization, governments typically utilize hybrid and permissioned designs that allow for selective decentralization alongside centralized oversight, a pattern we conceptualize as \"controlled polycentricity.\" By reframing blockchain as a governance infrastructure that encodes rules for coordination and information-sharing, this study advances digital government theory beyond simple adoption metrics. The findings offer theoretically grounded insights for researchers and practical guidance for policymakers seeking to design and scale sustainable blockchain-enabled public services.",
      "domain": "cs",
      "subdomain": "cs.SI",
      "category": "sociology"
    },
    {
      "paper_id": 639,
      "arxiv_id": "2602.03969v1",
      "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem",
      "abstract": "The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration.",
      "domain": "cs",
      "subdomain": "cs.SI",
      "category": "sociology"
    },
    {
      "paper_id": 641,
      "arxiv_id": "2602.03775v1",
      "title": "An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents",
      "abstract": "Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.",
      "domain": "cs",
      "subdomain": "cs.SI",
      "category": "sociology"
    },
    {
      "paper_id": 939,
      "arxiv_id": "2601.12854v1",
      "title": "A generalized work theorem for stopped stochastic chemical reaction networks",
      "abstract": "We establish a generalized work theorem for stochastic chemical reaction networks (CRNs). By using a compensated Poisson jump process, we identify a martingale structure in a generalized entropy defined relative to an auxiliary backward process and extend nonequilibrium work relations to processes stopped at bounded arbitrary times. Our results apply to discrete, mesoscopic chemical reaction networks and remain valid for singular initial conditions and state-dependent termination events. We show how martingale properties emerge directly from the structure of reaction propensities without assuming detailed balance. Stochastic simulations of a simple chemical kinetic proofreading network are used to explore the dependence of the exponentiated entropy production on initial conditions and model parameters, validating our new work theorem relationships. Our results provide new quantitative tools for analyzing biological circuits ranging from metabolic to gene regulation pathways.",
      "domain": "q-bio",
      "subdomain": "q-bio.MN",
      "category": "biology"
    },
    {
      "paper_id": 992,
      "arxiv_id": "2601.01850v2",
      "title": "Allostery Beyond Amplification: Temporal Regulation of Signaling Information",
      "abstract": "Allostery is a fundamental mechanism of protein regulation and is commonly interpreted as modulating enzymatic activity or product abundance. Here we show that this view is incomplete. Using a stochastic model of allosteric regulation combined with an information-theoretic analysis, we quantify the mutual information between an enzyme's regulatory state and the states of downstream signaling components. Beyond controlling steady-state production levels, allostery also regulates the timing and duration over which information is transmitted. By tuning the temporal operating regime of signaling pathways, allosteric regulation enables distinct dynamical outcomes from identical molecular components, providing a physical mechanism for temporal information flow, signaling specificity, and coordination without changes in metabolic pathways.",
      "domain": "q-bio",
      "subdomain": "q-bio.MN",
      "category": "biology"
    },
    {
      "paper_id": 796,
      "arxiv_id": "2512.03191v1",
      "title": "A Comprehensive Review of Casein Kinase 2 in Drosophila Circadian Timing and Its Biomedical Relevance",
      "abstract": "Circadian rhythms are endogenous 24-hour oscillations that regulate physiology, metabolism, sleep-wake cycles, and cellular homeostasis. Drosophila melanogaster, a genetically tractable model organism, has played a foundational role in uncovering the molecular mechanisms of circadian rhythms. The discovery of major clock genes, including period (per), timeless (tim), clock (clk), cycle (cyc), double time (dbt), and regulators such as Casein kinase 2 (CK2), emerged primarily from Drosophila research. CK2 operates as a critical post-translational regulator of PER protein phosphorylation, stability, nuclear entry, and degradation. Because PER dynamics dictate the timing and robustness of circadian rhythms in both flies and mammals, altered CK2 activity can profoundly impact rhythmic behaviour. CK2 dysregulation contributes not only to circadian disruption in Drosophila but also models broader pathological processes relevant to cancer, metabolic disease, neurodegeneration, and psychiatric disorders. This review synthesises CK2's molecular role in the Drosophila clock system, includes insights from computational modelling of CK2-PER dynamics, integrates tables throughout the text, and summarises the implications of dysregulated PER phosphorylation for human health.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 528,
      "arxiv_id": "2601.14509v1",
      "title": "Cell proliferation maintains cell area polydispersity in the growing fruit fly wing epithelium",
      "abstract": "Developing epithelial tissues coordinate cell proliferation and mechanical forces to achieve proper size and shape. As epithelial cells tightly adhere together to form the confluent tissue, the distribution of cell areas significantly influences possible patterns of cellular packing and thereby also the mechanics of the epithelium. Therefore, it is important to understand the origin of cell area heterogeneity in developing tissues and, if possible, how to control it. Previous models of cell growth and division have been successful in accounting for experimentally observed area distributions in cultured cells and bacterial colonies, but developing tissues present additional complexity due to self-organized patterns of mechanical stresses that guide morphogenesis. Here, we address this challenge focusing on the D. melanogaster wing disc epithelium. We consider a simple model that couples cell cycle dynamics to tissue mechanics. From time-lapse imaging of the cellular network, we extract all model parameters - cell growth rates, division rates, and mechanical fluctuations - revealing that they all depend on cell size. With these independently measured parameters, our model quantitatively reproduces the observed cell area distribution without any fitting parameters and further predicts tissue pressure gradients, in quantitative agreement with previously published data. Importantly, we find that cell proliferation accounts for 85% of cell area variance, establishing it as the dominant source of packing disorder that influences tissue mechanics and organization.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 529,
      "arxiv_id": "2601.08975v1",
      "title": "Stability and robustness of a generalized pump-leak model for epithelial cell and lumen volume regulation",
      "abstract": "Epithelial cells regulate ion concentrations and volume through coordinated membrane pumps, ion channels, and paracellular pathways which can be modeled by classical single-compartment pump-leak equations (PLEs). Many epithelial functions, however, depend on the interaction between a cell and an enclosed luminal space, a geometry that cannot be captured by classical PLEs. To address this, we develop a two-compartment model consisting of an intracellular compartment coupled to a luminal compartment through the apical membrane, with both compartments interfacing an infinite extracellular bath and connected to it through the basolateral membrane and a paracellular pathway. Building on the five-dimensional single-cell PLEs, we formulate a ten-dimensional PLE system for this geometry and derive analytical equilibria and steady-state formulas for both the passive system and the Na+/K+-ATPase (NKA) driven active system. We characterize how these equilibria depend on physiologically relevant parameters, analyze local stability across wide parameter ranges, and apply global sensitivity and robustness methods to identify the principal determinants of ion and volume homeostasis. The model reveals fundamental differences between basolateral and apical placement of the NKA, including the onset of luminal volume blow-up when apical potassium recycling is insufficient. More broadly, this framework provides a mathematically tractable and physiologically grounded foundation for studying epithelial transport and for predicting conditions under which pump localization and conductance changes lead to stable function or pathological lumen expansion.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 532,
      "arxiv_id": "2601.04335v1",
      "title": "Thermodynamic Constraints Drive Hierarchical Preemption in Cellular Decision-Making: A Hybrid Petri Net Framework with Application to Bacillus subtilis Sporulation",
      "abstract": "Cellular decision-making under stress involves rapid pathway selection despite energy scarcity. Here we demonstrate that thermodynamic constraints actively drive energy-efficient sporulation, where continuous metabolic sources enable system robustness through dynamic energy management. Using hybrid Petri nets (stochastic transitions with continuous sources) to model Bacillus subtilis sporulation, we show that stress conditions (ATP = 300 mM, 94% depletion) enable sporulation completion with extreme energy efficiency: 0.73 mM ATP per mature spore versus 11.6 mM ATP under normal conditions--a 16-fold efficiency gain. Despite ATP dropping to 1 mM (99.7% depletion) during the crisis, continuous ATP regeneration rescues the system, producing 67 mM mature spores (89% of normal yield) with only 49 mM total ATP consumption. This efficiency emerges from the interplay between stochastic regulatory transitions and continuous metabolic sources, where GTP accumulation (+4974 mM, 166% increase) provides an energy buffer while ATP regeneration (+240 mM) prevents complete depletion. The hybrid Petri net formalism--combining stochastic transitions for regulatory events with continuous sources for metabolic flux--extended with thermodynamic constraints through inhibitor arcs and energy-coupled rate functions, provides the mathematical foundation enabling this discovery by integrating discrete regulatory logic with continuous energy dynamics in a resource-aware concurrency model.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 538,
      "arxiv_id": "2512.13084v1",
      "title": "FlowClass.jl: Classifying Dynamical Systems by Structural Properties in Julia",
      "abstract": "FlowClass.jl is a Julia package for classifying continuous-time dynamical systems into a hierarchy of structural classes: Gradient, Gradient-like, Morse-Smale, Structurally Stable, and General. Given a vector field \\(\\mathbf{F}(\\mathbf{x})\\) defining the system \\(\\mathrm{d}\\mathbf{x}/\\mathrm{d}t = \\mathbf{F}(\\mathbf{x})\\), the package performs a battery of computational tests -- Jacobian symmetry analysis, curl magnitude estimation, fixed point detection and stability classification, periodic orbit detection, and stable/unstable manifold computation -- to determine where the system sits within the classification hierarchy. This classification has direct implications for qualitative behaviour: gradient systems cannot oscillate, Morse-Smale systems are structurally stable in less than 3 dimensions, and general systems may exhibit chaos. Much of classical developmental theory going back to Waddington's epigenetic landscape rests on an implicit assumption of gradient dynamics.\n  The package is designed with applications in systems and developmental biology in mind, particularly the analysis of gene regulatory networks and cell fate decision models in the context of Waddington's epigenetic landscape. It provides tools to assess whether a landscape metaphor is appropriate for a given dynamical model, and to quantify the magnitude of non-gradient (curl) dynamics.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 540,
      "arxiv_id": "2512.08024v1",
      "title": "Coarse-graining and stochastic oscillations in a phenomenological model of cell-size homeostasis",
      "abstract": "Within a continuous-time, stochastic model of single-cell size homeostasis, we study how the structure of feedback from size to growth rates and cell-cycle progression shapes overall size dynamics, both within and across cell cycles. We focus on a model in which the feedback from cell size to these other processes occurs only through the size deviations, defined as the difference between the absolute size and the progression through the cell cycle. In a linear regime of this model, the dynamics reduce to a stochastically forced simple harmonic oscillator, yielding closed-form expressions for mother-daughter size correlations. We compare these to the higher order regression coefficients that measure the size memory over many generations. Our analysis reveals how the interplay between cell-cycle timing and intrinsic fluctuations shapes the apparent coarse-grained size control strategy, and in-particular, that coarse-grained correlations may not reflect the mechanistic feedback structure. We compare this model to a more commonly used approach where the coarse-grained dynamics are hard-coded into the model; hence, the first order autoregressive model for sizes is a perfect description of the size dynamics and therefore more accurately reflects the feedback structure.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 543,
      "arxiv_id": "2512.03497v1",
      "title": "Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities",
      "abstract": "In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 789,
      "arxiv_id": "2601.21643v1",
      "title": "Computational investigation of single herbal drugs in Ayurveda for diabetes and obesity using knowledge graph and network pharmacology",
      "abstract": "Metabolic diseases such as type 2 diabetes and obesity represent a rapidly escalating global health burden, yet current therapeutic strategies largely target isolated symptoms or single molecular pathways. To this end, we developed an integrated computational pipeline leveraging knowledge graph, pathway analysis and network pharmacology to elucidate the multi-target mechanisms of Ayurvedic Single Herbal Drugs (SHDs). SHDs associated with diabetes and obesity were curated from the Ayurvedic Pharmacopoeia of India, followed by phytochemical identification using IMPPAT database, yielding a shortlist of 11 SHDs and their 188 phytochemicals after drug-likeness and bioavailability filtering. Subsequently, molecular targets of the phytochemicals in SHDs, disease-associated genes and therapeutic targets of FDA-approved drugs, were curated via integration of data from several databases. Pathway enrichment analysis revealed significant functional overlap between SHD-associated and disease-associated pathways. All curated data were embedded into a Neo4j-based knowledge graph, enabling SHD-disease intersection analysis that prioritized key disease-relevant targets, including PTPN1, GLP1R, and DPP4. Also, the SHD-Target-FDA-approved drug profile elucidated the molecular and mechanistic aspects of the SHDs as a phytochemical cocktail, and is in alignment with the clinically studied synergistic FDA-approved drug combinations. Network pharmacology based protein-protein interaction analysis identified PPARG as another central regulator. Using a quantitative framework, we identified phytochemical pairs within SHDs, which were structurally dissimilar and target-wise distinct, yet acted on shared or different disease-associated pathways, indicating complementary and potentially synergistic interactions. Molecular docking analysis of two selected druggable targets identified putative lead phytochemicals.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 791,
      "arxiv_id": "2512.21455v1",
      "title": "Distributed delay stabilizes bistable genetic networks",
      "abstract": "Delay is an inherent feature of genetic regulatory networks. It represents the time required for the assembly of functional regulator proteins. The protein production process is complex, as it includes transcription, translocation, translation, folding, and oligomerization. Because these steps are noisy, the resulting delay associated with protein production is distributed (random). We here consider how distributed delay impacts the dynamics of bistable genetic circuits. We show that for a variety of genetic circuits that exhibit bistability, increasing the noise level in the delay distribution dramatically stabilizes the metastable states. By this we mean that mean residence times in the metastable states dramatically increase.\n  Relevance to Life Sciences. Bistable genetic regulatory networks are ubiquitous in living organisms. Evolutionary processes seem to have tuned such networks so that they switch between metastable states when it is important to do so, but small fluctuations do not cause unwanted switching. Understanding how evolution has tuned the stability of biological switches is an important problem. In particular, such understanding can guide the design of forward-engineered synthetic bistable genetic regulatory networks.\n  Mathematical Content. We use two methods to explain this stabilization phenomenon. First, we introduce and simulate stochastic hybrid models that depend on a switching-rate parameter. These stochastic hybrid models allow us to unfold the distributed-delay models in the sense that, in certain cases, the distributed-delay model can be viewed as a fast-switching limit of the corresponding stochastic hybrid model. Second, we generalize the three-states model, a symbolic model of bistability, and analyze this extension.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 794,
      "arxiv_id": "2512.08732v1",
      "title": "Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data",
      "abstract": "The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadriven simulation systems are critical in this landscape; unlike classical mechanistic models restricted by prior knowledge, these architectures can infer latent interactions directly from observational data, allowing for the simulation of temporal trajectories and the anticipation of downstream intervention effects in personalized medicine and synthetic biology. To address this challenge, we introduce Neural Ordinary Differential Equations (NODEs) as a dynamic framework for learning the complex interplay between the proteome and metabolome. We applied this framework to time-series data derived from engineered Escherichia coli strains, modeling the continuous dynamics of metabolic pathways. The proposed NODE architecture demonstrates superior performance in capturing system dynamics compared to traditional machine learning pipelines. Our results show a greater than 90% improvement in root mean squared error over baselines across both Limonene (up to 94.38% improvement) and Isopentenol (up to 97.65% improvement) pathway datasets. Furthermore, the NODE models demonstrated a 1000x acceleration in inference time, establishing them as a scalable, high-fidelity tool for the next generation of metabolic engineering and biological discovery.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 797,
      "arxiv_id": "2512.02908v1",
      "title": "Imperfect molecular detection renormalizes apparent kinetic rates in stochastic gene regulatory networks",
      "abstract": "Imperfect molecular detection in single-cell experiments introduces technical noise that obscures the true stochastic dynamics of gene regulatory networks. While binomial models of molecular capture provide a principled description of imperfect detection, they have so far been analyzed only for simple gene-expression models that do not explicitly account for regulation. Here, we extend binomial models of capture to general gene regulatory networks to understand how imperfect capture reshapes the observed time-dependent statistics of molecular counts. Our results reveal when capture effects correspond to a renormalization of a subset of the kinetic rates and when they cannot be absorbed into effective rates, providing a systematic basis for interpreting noisy single-cell measurements. In particular, we show that rate renormalization emerges either under significant transcription factor abundance or when promoter-state transitions occur on a distinct (much slower or faster) timescale than other reactions. In these cases, technical noise causes the apparent mean burst size of synthesized gene products to appear reduced while transcription factor binding reactions appear faster. These effects hold for gene regulatory networks of arbitrary connectivity and remain valid under time-dependent kinetic rates.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 799,
      "arxiv_id": "2511.23344v1",
      "title": "A theory for coexistence and selection of branched actin networks in a shared and finite pool of monomers",
      "abstract": "Cellular actin structures are continuously turned over while keeping similar sizes. Since they all compete for a shared pool of actin monomers, the question arises how they can coexist in these dynamic steady states. Recently, the coexistence of branched actin networks with different densities growing in a shared and finite pool of purified proteins has been demonstrated in a biomimetic bead assay. However, theoretical work in the context of organelle size regulation has mainly been focused on linear architectures, such as single filaments and bundles, and thus is not able to explain this observation. Here we show theoretically that the local depletion of actin monomers caused by the growth of a branched network naturally gives rise to a negative feedback loop between network density and growth rate, and that this competition is captured by one central equation. A comprehensive bifurcation analysis shows that the theory leads to well-defined steady states even in the case of multiple networks sharing the same pool of monomers, without any need for specific molecular processes. Under increasing competition strength, coexistence is replaced by selection. We also show that our theory is in excellent agreement with spatiotemporal simulations implemented in a finite element framework. In summary, our work suggests that local monomer depletion is the decisive and universal factor controlling growth of branched actin networks.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 937,
      "arxiv_id": "2601.17582v1",
      "title": "GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design",
      "abstract": "Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.",
      "domain": "q-bio",
      "subdomain": "q-bio.MN",
      "category": "biology"
    },
    {
      "paper_id": 377,
      "arxiv_id": "2602.03886v1",
      "title": "Prenatal Stress Detection from Electrocardiography Using Self-Supervised Deep Learning: Development and External Validation",
      "abstract": "Prenatal psychological stress affects 15-25% of pregnancies and increases risks of preterm birth, low birth weight, and adverse neurodevelopmental outcomes. Current screening relies on subjective questionnaires (PSS-10), limiting continuous monitoring. We developed deep learning models for stress detection from electrocardiography (ECG) using the FELICITy 1 cohort (151 pregnant women, 32-38 weeks gestation). A ResNet-34 encoder was pretrained via SimCLR contrastive learning on 40,692 ECG segments per subject. Multi-layer feature extraction enabled binary classification and continuous PSS prediction across maternal (mECG), fetal (fECG), and abdominal ECG (aECG). External validation used the FELICITy 2 RCT (28 subjects, different ECG device, yoga intervention vs. control). On FELICITy 1 (5-fold CV): mECG 98.6% accuracy (R2=0.88, MAE=1.90), fECG 99.8% (R2=0.95, MAE=1.19), aECG 95.5% (R2=0.75, MAE=2.80). External validation on FELICITy 2: mECG 77.3% accuracy (R2=0.62, MAE=3.54, AUC=0.826), aECG 63.6% (R2=0.29, AUC=0.705). Signal quality-based channel selection outperformed all-channel averaging (+12% R2 improvement). Mixed-effects models detected a significant intervention response (p=0.041). Self-supervised deep learning on pregnancy ECG enables accurate, objective stress assessment, with multi-layer feature extraction substantially outperforming single embedding approaches.",
      "domain": "q-bio",
      "subdomain": "q-bio.QM",
      "category": "biology"
    },
    {
      "paper_id": 533,
      "arxiv_id": "2601.01728v1",
      "title": "An AI-guided mechanotyping instrument for fully automated oocyte quality assessment",
      "abstract": "The mechanical properties of oocytes are regarded as important indicators of their developmental potential. During fertilization, deviations from the normal mechanical range can hinder sperm penetration, ultimately reducing fertilization efficiency and compromising embryo quality. However, current methods for measuring oocyte mechanics often suffer from serious cellular damage, low automation levels, and large measurement errors. To address these limitations, we developed an AI-guided micronewton-scale mechanical measurement system for safe and automated oocyte quality assessment. The system integrates voice interaction with automated experimental workflows to control a magnetically actuated microgripper, which applies defined loading forces to induce micron-scale compressive deformation of the oocyte. Combined with AI-assisted object detection and image segmentation algorithms, the system captures cellular deformation in real time, enabling precise calculation of the oocyte's compressive modulus. This measurement system enables automated, quantitative, and non-destructive evaluation of oocyte mechanical properties, providing an effective approach for oocyte quality screening in in vitro fertilization (IVF) and other assisted reproductive technologies (ART).",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 539,
      "arxiv_id": "2512.12406v1",
      "title": "Morphogenesis of bacterial colonies in liquid crystalline environments",
      "abstract": "Natural bacterial habitats are often complex fluids with viscoelastic and anisotropic responses to stress; for example, they can take the form of liquid crystals (LCs), with elongated microscopic constituents that collectively align while still retaining the ability to flow. However, laboratory studies typically focus on cells in simple liquids or complex fluids with randomly-oriented constituents. Here, we show how interactions with LCs shape bacterial proliferation in multicellular colonies. Using experiments, we find that in a nematic LC, cells generically form aligned single-cell-wide \"chains\" as they reproduce. As these chains lengthen, they eventually buckle in a highly localized manner. By combining our measurements with a continuum mechanical theory, we demonstrate that this distinctive morphogenetic program emerges because cells are kept in alignment due to the LC's elasticity; as each chain lengthens, growth-induced viscous stresses along its contour eventually overcome the elasticity of the surrounding nematic, leading to buckling. Our work thus reveals and provides mechanistic insight into the previously-overlooked role of LCs in sculpting bacterial life in complex environments.",
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "category": "biology"
    },
    {
      "paper_id": 795,
      "arxiv_id": "2512.08087v1",
      "title": "Subcellular proteome niche discovery using semi-supervised functional clustering",
      "abstract": "Intracellular compartmentalization of proteins underpins their function and the metabolic processes they sustain. Various mass spectrometry-based proteomics methods (subcellular spatial proteomics) now allow high throughput subcellular protein localization. Yet, the curation, analysis and interpretation of these data remain challenging, particularly in non-model organisms where establishing reliable marker proteins is difficult, and in contexts where experimental replication and subcellular fractionation are constrained. Here, we develop FSPmix, a semi-supervised functional clustering method implemented as an open-source R package, which leverages partial annotations from a subset of marker proteins to predict protein subcellular localization from subcellular spatial proteomics data. This method explicitly assumes that protein signatures vary smoothly across subcellular fractions, enabling more robust inference under low signal-to-noise data regimes. We applied FSPmix to a subcellular proteomics dataset from a marine diatom, allowing us to assign probabilistic localizations to proteins and uncover potentially new protein functions. Altogether, this work lays the foundation for more robust statistical analysis and interpretation of subcellular proteomics datasets, particularly in understudied organisms.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    },
    {
      "paper_id": 798,
      "arxiv_id": "2512.01417v2",
      "title": "Active Force Dynamics in Red Blood Cells Under Non-Invasive Optical Tweezers",
      "abstract": "Red blood cells (RBCs) sustain mechanical stresses associated with microcirculatory flow through ATP-driven plasma membrane flickering. This is an active phenomenon driven by motor proteins that regulate interactions between the spectrin cytoskeleton and the lipid bilayer; it is manifested in RBC shape fluctuations reflecting the cell's mechanical and metabolic state. Yet, direct quantification of the forces and energetic costs underlying this non-equilibrium behavior remains challenging due to the invasiveness of existing techniques. Here, a minimally invasive method that combines bead-free, low-power optical tweezers with high-speed video microscopy was employed to track local membrane forces and displacements in single RBCs during the same time window. This independent dual-channel measurement enabled the construction of a mechano-dynamic phase space for RBCs under different chemical treatments, that allowed for differentiating between metabolic and structural states based on their fluctuation-force signatures. Quantification of mechanical work during flickering demonstrated that membrane softening enhanced fluctuations while elevating energy dissipation. The proposed optical tweezers methodology provides a robust framework for mapping the active mechanics of living cells, enabling precise probing of cellular physiology and detection of biomechanical dysfunction in diseases.",
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "category": "biology"
    }
  ]
}