[
  {
    "paper_id": 638,
    "title": "Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach",
    "abstract": "Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.",
    "domain": "cs",
    "arxiv_id": "2602.04116v1",
    "score": 9
  },
  {
    "paper_id": 872,
    "title": "History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis",
    "abstract": "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.",
    "domain": "q-fin",
    "arxiv_id": "2601.10143v1",
    "score": 9
  },
  {
    "paper_id": 941,
    "title": "PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network",
    "abstract": "Drug discovery represents a time-consuming and financially intensive process, and virtual screening can accelerate it. Scoring functions, as one of the tools guiding virtual screening, have their precision closely tied to screening efficiency. In our previous study, we developed a graph neural network model called PLANET (Protein-Ligand Affinity prediction NETwork), but it suffers from the defect in representing protein-ligand contact maps. Incorrect binding modes inevitably lead to poor affinity predictions, so accurate prediction of the protein-ligand contact map is desired to improve PLANET. In this study, we have proposed PLANET v2.0 as an upgraded version. The model is trained via multi-objective training strategy and incorporates the Mixture Density Network to predict binding modes. Except for the probability density distributions of non-covalent interactions, we innovatively employ another Gaussian mixture model to describe the relationship between distance and energy of each interaction pair and predict protein-ligand affinity like calculating the mathematical expectation. As on the CASF-2016 benchmark, PLANET v2.0 demonstrates excellent scoring power, ranking power, and docking power. The screening power of PLANET v2.0 gets notably improved compared to PLANET and Glide SP and it demonstrates robust validation on a commercial ultra-large-scale dataset. Given its efficiency and accuracy, PLANET v2.0 can hopefully become one of the practical tools for virtual screening workflows. PLANET v2.0 is freely available at https://www.pdbbind-plus.org.cn/planetv2.",
    "domain": "q-bio",
    "arxiv_id": "2601.07415v1",
    "score": 9
  },
  {
    "paper_id": 997,
    "title": "On Dual Connectivity in 6G Leo Constellations",
    "abstract": "Dual connectivity (DC) has garnered significant attention in 5G evolution, allowing for enhancing throughput and reliability by leveraging the channel conditions of two paths. However, when the paths exhibit different delays, such as in terrestrial and non-terrestrial integrated networks with multi-orbit topologies or in networks characterized by frequent topology changes, like Low Earth Orbit (LEO) satellite constellations with different elevation angles, traffic delivery may experience packet reordering or triggering congestion control mechanisms. Additionally, real-time traffic may experience packet drops if their arrival exceeds a play-out threshold. Different techniques have been proposed to address these issues, such as packet duplication, packet switching, and network coding for traffic scheduling in DC. However, if not accurately designed, these techniques can lead to resource waste, encoding/decoding delays, and computational overhead, undermining DC's intended benefits. This paper provides a mathematical framework for calculating the average end-to-end packet loss in case of a loss process modeled with a Discrete Markov Chain - typical of a wireless channel - when combining packet duplication and packet switching or when network coding is employed in DC. Such metrics help derive optimal policies with full knowledge of the underlying loss process to be compared to empirical models learned through Machine Learning algorithms.",
    "domain": "cs",
    "arxiv_id": "2602.04825v1",
    "score": 9
  },
  {
    "paper_id": 1353,
    "title": "Restoring Sparsity in Potts Machines via Mean-Field Constraints",
    "abstract": "Ising machines and related probabilistic hardware have emerged as promising platforms for NP-hard optimization and sampling. However, many practical problems involve constraints that induce dense or all-to-all couplings, undermining scalability and hardware efficiency. We address this constraint-induced density through two complementary approaches. First, we introduce a hardware-aware native formulation for multi-state probabilistic digits (p-dits) that avoids the locally dense intra-variable couplings required by binary Ising encodings. We validate p-dit dynamics by reproducing known critical behavior of the 2D Potts model. Second, we propose mean-field constraints (MFC), a hybrid scheme that replaces dense pairwise constraint couplings with dynamically updated single-node biases. Applied to balanced graph partitioning, MFC achieves solution quality comparable to exact all-to-all constraint formulations while dramatically reducing graph density. Finally, we demonstrate the practical impact of restored sparsity by an FPGA implementation, enabling orders-of-magnitude acceleration over CPU-based solvers. Together, these results outline a pathway for scaling constrained optimization on probabilistic hardware.",
    "domain": "cs",
    "arxiv_id": "2602.04200v1",
    "score": 9
  },
  {
    "paper_id": 1540,
    "title": "Optimal Learning-Rate Schedules under Functional Scaling Laws: Power Decay and Warmup-Stable-Decay",
    "abstract": "We study optimal learning-rate schedules (LRSs) under the functional scaling law (FSL) framework introduced in Li et al. (2025), which accurately models the loss dynamics of both linear regression and large language model (LLM) pre-training. Within FSL, loss dynamics are governed by two exponents: a source exponent $s>0$ controlling the rate of signal learning, and a capacity exponent $\u03b2>1$ determining the rate of noise forgetting. Focusing on a fixed training horizon $N$, we derive the optimal LRSs and reveal a sharp phase transition. In the easy-task regime $s \\ge 1 - 1/\u03b2$, the optimal schedule follows a power decay to zero, $\u03b7^*(z) = \u03b7_{\\mathrm{peak}}(1 - z/N)^{2\u03b2- 1}$, where the peak learning rate scales as $\u03b7_{\\mathrm{peak}} \\eqsim N^{-\u03bd}$ for an explicit exponent $\u03bd= \u03bd(s,\u03b2)$. In contrast, in the hard-task regime $s < 1 - 1/\u03b2$, the optimal LRS exhibits a warmup-stable-decay (WSD) (Hu et al. (2024)) structure: it maintains the largest admissible learning rate for most of training and decays only near the end, with the decay phase occupying a vanishing fraction of the horizon.\n  We further analyze optimal shape-fixed schedules, where only the peak learning rate is tuned -- a strategy widely adopted in practiceand characterize their strengths and intrinsic limitations. This yields a principled evaluation of commonly used schedules such as cosine and linear decay. Finally, we apply the power-decay LRS to one-pass stochastic gradient descent (SGD) for kernel regression and show the last iterate attains the exact minimax-optimal rate, eliminating the logarithmic suboptimality present in prior analyses. Numerical experiments corroborate our theoretical predictions.",
    "domain": "stat",
    "arxiv_id": "2602.06797v1",
    "score": 9
  },
  {
    "paper_id": 1565,
    "title": "AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models",
    "abstract": "Reinforcement learning from human feedback (RLHF) shows promise for aligning diffusion and flow models, yet policy optimization methods such as GRPO suffer from inefficient and static sampling strategies. These methods treat all prompts and denoising steps uniformly, ignoring substantial variations in sample learning value as well as the dynamic nature of critical exploration moments.\n  To address this issue, we conduct a detailed analysis of the internal attention dynamics during GRPO training and uncover a key insight: attention entropy can serve as a powerful dual-signal proxy. First, across different samples, the relative change in attention entropy (\u0394Entropy), which reflects the divergence between the current policy and the base policy, acts as a robust indicator of sample learning value. Second, during the denoising process, the peaks of absolute attention entropy (Entropy(t)), which quantify attention dispersion, effectively identify critical timesteps where high-value exploration occurs.\n  Building on this observation, we propose Adaptive Entropy-Guided Policy Optimization (AEGPO), a novel dual-signal, dual-level adaptive optimization strategy. At the global level, AEGPO uses \u0394Entropy to dynamically allocate rollout budgets, prioritizing prompts with higher learning value. At the local level, it exploits the peaks of Entropy(t) to guide exploration selectively at critical high-dispersion timesteps rather than uniformly across all denoising steps.\n  By focusing computation on the most informative samples and the most critical moments, AEGPO enables more efficient and effective policy optimization. Experiments on text-to-image generation tasks demonstrate that AEGPO significantly accelerates convergence and achieves superior alignment performance compared to standard GRPO variants.",
    "domain": "cs",
    "arxiv_id": "2602.06825v1",
    "score": 9
  },
  {
    "paper_id": 1629,
    "title": "Optimal Control Strategies for Epidemic Dynamics: Integrating SIR-SI and Lotka--Volterra Models",
    "abstract": "In this work we present a mathematical model that integrates the epidemiological dynamics of a vector-borne disease (SIR-SI) with Lotka Volterra predator prey ecological interactions. The study analyzes how the presence of natural predators acts as a biological control mechanism to regulate the vector population and, consequently, disease transmission in host. \nWe introduce the concept of the ecological reproduction number, a threshold that links the amplitude of predator prey cycles to disease persistence, showing that natural control depends critically on the ratio between the maximum vector density and the minimum predator density. In scenarios where natural control is insufficient, we formulate an optimal control problem based on the release of predators. Using the Pontryagin Maximum Principle, we characterize the optimal strategy that minimizes the cumulative number of infected individuals and intervention costs, while simultaneously maximizing the susceptible host population at the end of the time horizon. Numerical simulations validate the effectiveness of the model, showing that external intervention mitigates the epidemic peak and stabilizes the system against the natural oscillations of biological populations.",
    "domain": "math",
    "arxiv_id": "2602.06178v1",
    "score": 9
  },
  {
    "paper_id": 1744,
    "title": "Improve Large Language Model Systems with User Logs",
    "abstract": "Scaling training data and model parameters has long driven progress in large language models (LLMs), but this paradigm is increasingly constrained by the scarcity of high-quality data and diminishing returns from rising computational costs. As a result, recent work is increasing the focus on continual learning from real-world deployment, where user interaction logs provide a rich source of authentic human feedback and procedural knowledge. However, learning from user logs is challenging due to their unstructured and noisy nature. Vanilla LLM systems often struggle to distinguish useful feedback signals from noisy user behavior, and the disparity between user log collection and model optimization (e.g., the off-policy optimization problem) further strengthens the problem. To this end, we propose UNO (User log-driveN Optimization), a unified framework for improving LLM systems (LLMsys) with user logs. UNO first distills logs into semi-structured rules and preference pairs, then employs query-and-feedback-driven clustering to manage data heterogeneity, and finally quantifies the cognitive gap between the model's prior knowledge and the log data. This assessment guides the LLMsys to adaptively filter out noisy feedback and construct different modules for primary and reflective experiences extracted from user logs, thereby improving future responses. Extensive experiments show that UNO achieves state-of-the-art effectiveness and efficiency, significantly outperforming Retrieval Augmented Generation (RAG) and memory-based baselines. We have open-sourced our code at https://github.com/bebr2/UNO .",
    "domain": "cs",
    "arxiv_id": "2602.06470v1",
    "score": 9
  },
  {
    "paper_id": 1985,
    "title": "Convex Hull 3D Filtering with GPU Ray Tracing and Tensor Cores",
    "abstract": "In recent years, applications such as real-time simulations, autonomous systems, and video games increasingly demand the processing of complex geometric models under stringent time constraints. Traditional geometric algorithms, including the convex hull, are subject to these challenges. A common approach to improve performance is scaling computational resources, which often results in higher energy consumption. Given the growing global concern regarding sustainable use of energy, this becomes a critical limitation. This work presents a 3D preprocessing filter for the convex hull algorithm using ray tracing and tensor core technologies. The filter builds a delimiter polyhedron based on Manhattan distances that discards points from the original set. The filter is evaluated on two point distributions: uniform and sphere. Experimental results show that the proposed filter, combined with convex hull construction, accelerates the computation of the 3D convex hull by up to 200x with respect to a CPU parallel implementation. This research demonstrates that geometric algorithms can be accelerated through massive parallelism while maintaining efficient energy utilization. Beyond execution time and speedup evaluation, we also analyze GPU energy consumption, showing that the proposed preprocessing filter not only reduces the computational workload but also achieves performance gains with controlled energy usage. These results highlight the dual benefit of the method in terms of both speed and energy efficiency, reinforcing its applicability in modern high-performance scenarios.",
    "domain": "cs",
    "arxiv_id": "2601.19647v2",
    "score": 9
  },
  {
    "paper_id": 2068,
    "title": "Impulsive Release Strategies for Wolbachia-Infected Mosquitoes under Temperature-Induced Infection Loss",
    "abstract": "The release of Wolbachia-infected mosquitoes is a promising strategy for controlling Aedes aegypti populations, but exposure to high temperatures can induce temporary infection loss and compromise long-term persistence. In this work, we propose a population-dynamics model based on impulsive differential equations to describe the interaction between wild and infected mosquitoes, incorporating cytoplasmic incompatibility, periodic release interventions, and temperature-driven infection loss. Analytical threshold conditions are derived to characterize the existence and stability of periodic solutions associated with successful Wolbachia establishment. Numerical simulations illustrate the theoretical results and enable a comparative analysis of the wMelPop, wMel, and wAlbB strains, highlighting how differences in thermal tolerance and fitness costs influence persistence after the release phase. The results emphasize the importance of accounting for environmental stress and impulsive interventions when designing effective and robust Wolbachia release strategies.",
    "domain": "q-bio",
    "arxiv_id": "2602.07231v1",
    "score": 9
  },
  {
    "paper_id": 32,
    "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
    "abstract": "Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently reason about similar sub-problems or execute analogous steps, they repeatedly perform substantial overlapping computation. To address these limitations, in this paper, we propose Learning to Share (LTS), a learned shared-memory mechanism for parallel agentic frameworks that enables selective cross-team information reuse while controlling context growth. LTS introduces a global memory bank accessible to all teams and a lightweight controller that decides whether intermediate agent steps should be added to memory or not. The controller is trained using stepwise reinforcement learning with usage-aware credit assignment, allowing it to identify information that is globally useful across parallel executions. Experiments on the AssistantBench and GAIA benchmarks show that LTS significantly reduces overall runtime while matching or improving task performance compared to memory-free parallel baselines, demonstrating that learned memory admission is an effective strategy for improving the efficiency of parallel agentic systems. Project page: https://joefioresi718.github.io/LTS_webpage/",
    "domain": "cs",
    "arxiv_id": "2602.05965v1",
    "score": 8
  },
  {
    "paper_id": 125,
    "title": "GP-DHT: A Dual-Head Transformer with Contras-tive Learning for Predicting Gene Regulatory Rela-tionships across Species from Single-Cell Data",
    "abstract": "Gene regulatory networks (GRNs) are essential for understanding cell fate decisions and disease mechanisms, yet cross-species GRN inference from single-cell RNA-seq data remains challenging due to noise, sparsity, and cross-species distribution shifts. We propose GP-DHT (GenePair DualHeadTransformer), a cross-species single-cell GRN inference framework that models genes and cells in a heterogeneous graph with multi-level expression relations and learns structured regulatory representations via multi-relational graph attention. A dual-head Transformer further captures local gene pair regulatory dependencies and global cross-cell interaction patterns. To improve robustness under sparse and cross-species settings, GP-DHT introduces gene pair level supervised contrastive learning. Experiments on seven BEELINE benchmark datasets show consistent gains over representative baselines, improving AUROC and AUPRC by approximately 5 to 7 percent on most datasets. GP-DHT also recovers known regulatory modules and helps distinguish conserved from species-specific regulations.",
    "domain": "q-bio",
    "arxiv_id": "2601.10995v1",
    "score": 8
  },
  {
    "paper_id": 175,
    "title": "Imperfect Turing Patterns: Diffusiophoretic Assembly of Hard Spheres via Reaction-Diffusion Instabilities",
    "abstract": "Turing patterns are stationary, wave-like structures that emerge from the nonequilibrium assembly of reactive and diffusive components. While they are foundational in biophysics, their classical formulation relies on a single characteristic length scale that balances reaction and diffusion, making them overly simplistic for describing biological patterns, which often exhibit multi-scale structures, grain-like textures, and inherent imperfections. Here, we integrate diffusiophoretically-assisted assembly of finite-sized cells, driven by a background chemical gradient in a Turing pattern, while also incorporating intercellular interactions. This framework introduces key control parameters, such as the P\u00e9clet number, cell size distribution, and intercellular interactions, enabling us to reproduce strikingly similar structural features observed in natural patterns. We report imperfections, including spatial variations in pattern thickness, packing limits, and pattern breakups. Our model not only deepens our understanding but also opens a new line of inquiry into imperfect Turing patterns that deviate from the classical formulation in significant ways.",
    "domain": "physics",
    "arxiv_id": "2601.21180v1",
    "score": 8
  },
  {
    "paper_id": 321,
    "title": "RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference",
    "abstract": "The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \\underline{r}ound-\\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$\u03c4$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.",
    "domain": "cs",
    "arxiv_id": "2602.05853v1",
    "score": 8
  },
  {
    "paper_id": 323,
    "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena",
    "domain": "cs",
    "arxiv_id": "2602.05843v1",
    "score": 8
  },
  {
    "paper_id": 376,
    "title": "All-Atom GPCR-Ligand Simulation via Residual Isometric Latent Flow",
    "abstract": "G-protein-coupled receptors (GPCRs), primary targets for over one-third of approved therapeutics, rely on intricate conformational transitions to transduce signals. While Molecular Dynamics (MD) is essential for elucidating this transduction process, particularly within ligand-bound complexes, conventional all-atom MD simulation is computationally prohibitive. In this paper, we introduce GPCRLMD, a deep generative framework for efficient all-atom GPCR-ligand simulation.GPCRLMD employs a Harmonic-Prior Variational Autoencoder (HP-VAE) to first map the complex into a regularized isometric latent space, preserving geometric topology via physics-informed constraints. Within this latent space, a Residual Latent Flow samples evolution trajectories, which are subsequently decoded back to atomic coordinates. By capturing temporal dynamics via relative displacements anchored to the initial structure, this residual mechanism effectively decouples static topology from dynamic fluctuations. Experimental results demonstrate that GPCRLMD achieves state-of-the-art performance in GPCR-ligand dynamics simulation, faithfully reproducing thermodynamic observables and critical ligand-receptor interactions.",
    "domain": "q-bio",
    "arxiv_id": "2602.03902v1",
    "score": 8
  },
  {
    "paper_id": 422,
    "title": "Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization",
    "abstract": "Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SNN models with hardware-aware optimization for edge deployment. NeuEdge uses a temporal coding scheme that blends rate and spike-timing patterns to reduce spike activity while preserving accuracy, and a hardware-aware training procedure that co-optimizes network structure and on-chip placement to improve utilization on neuromorphic processors. An adaptive threshold mechanism adjusts neuron excitability from input statistics, reducing energy consumption without degrading performance. Across standard vision and audio benchmarks, NeuEdge achieves 91-96% accuracy with up to 2.3 ms inference latency on edge hardware and an estimated 847 GOp/s/W energy efficiency. A case study on an autonomous-drone workload shows up to 312x energy savings relative to conventional deep neural networks while maintaining real-time operation.",
    "domain": "cs",
    "arxiv_id": "2602.02439v1",
    "score": 8
  },
  {
    "paper_id": 469,
    "title": "The near-continuum mechanism for extended Boltzmann theory: the non-equilibrium relaxation",
    "abstract": "The collision phenomenon of polyatomic gases is described by the collision operator of extended Boltzmann equation or the energy-exchange model in particle direct simulations, for example, the Borgnakke-Larsen model. However, as a collision kernel, it dose not guarantee the entrinsic detailed balance and is not integrable. In this work, the Pullin equation, which possesses an integrable collision kernel and satisfies the detailed balance constraint, is adopted as an extended Boltzmann equation for the theoretical analysis of near-continuum relaxation mechanisms. For clarity, only the translational and rotational degrees are considered in this work. Explicit analytical expressions for the temporal relaxation of macroscopic variables, including the stress force, (translational/rotational) temperature and heat flux, are obtained at the first time. This is achieved by approximating the distribution function in mixed Hermite and Laguerre for rotation and computing the collision operator moments, enabling a direct description of macroscopic non-equilibrium evolution. Base on the same elementary moment (integral) of collision operator, the macroscopic transport coefficients is found in Chapman-Enskog framework. The long-standing speculation, that thermal conduction coefficient should be depended on the degrees of thermal non-equilibrium, is rigorously confirmed and evaluated. When thermal equilibrium is enforced, the present thermal conduction coefficients can be degenerated to the famous results of Mason and Monchick. Given the correct relaxation rate, a Rykov-type novel relaxation model for Pullin equation is proposed. It can recover the interaction of transaltional and rotatioanl heat fluxes in relaxation process, which is ignored in the widely used Rykov equation. Finally, the precision of this new Rykov-type equation is examined using a series of benchmark test cases.",
    "domain": "physics",
    "arxiv_id": "2602.05775v1",
    "score": 8
  },
  {
    "paper_id": 638,
    "title": "Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach",
    "abstract": "Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.",
    "domain": "cs",
    "arxiv_id": "2602.04116v1",
    "score": 9
  },
  {
    "paper_id": 674,
    "title": "Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy",
    "abstract": "The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as Google's Agent-to-Agent (A2A), they establish attack surfaces where manipulations can propagate through natural language payloads, potentially causing severe consequences ranging from driver distraction to unauthorized vehicle control. Existing AI security frameworks, while foundational, lack the rigorous \"separation of concerns\" standard in safety-critical systems engineering by co-mingling the concepts of what is being protected (assets) with how it is attacked (attack paths). This paper addresses this methodological gap by proposing a threat modeling framework called AgentHeLLM (Agent Hazard Exploration for LLM Assistants) that formally separates asset identification from attack path analysis. We introduce a human-centric asset taxonomy derived from harm-oriented \"victim modeling\" and inspired by the Universal Declaration of Human Rights, and a formal graph-based model that distinguishes poison paths (malicious data propagation) from trigger paths (activation actions). We demonstrate the framework's practical applicability through an open-source attack path suggestion tool AgentHeLLM Attack Path Generator that automates multi-stage threat discovery using a bi-level search strategy.",
    "domain": "cs",
    "arxiv_id": "2602.05877v1",
    "score": 8
  },
  {
    "paper_id": 872,
    "title": "History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis",
    "abstract": "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.",
    "domain": "q-fin",
    "arxiv_id": "2601.10143v1",
    "score": 9
  },
  {
    "paper_id": 941,
    "title": "PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network",
    "abstract": "Drug discovery represents a time-consuming and financially intensive process, and virtual screening can accelerate it. Scoring functions, as one of the tools guiding virtual screening, have their precision closely tied to screening efficiency. In our previous study, we developed a graph neural network model called PLANET (Protein-Ligand Affinity prediction NETwork), but it suffers from the defect in representing protein-ligand contact maps. Incorrect binding modes inevitably lead to poor affinity predictions, so accurate prediction of the protein-ligand contact map is desired to improve PLANET. In this study, we have proposed PLANET v2.0 as an upgraded version. The model is trained via multi-objective training strategy and incorporates the Mixture Density Network to predict binding modes. Except for the probability density distributions of non-covalent interactions, we innovatively employ another Gaussian mixture model to describe the relationship between distance and energy of each interaction pair and predict protein-ligand affinity like calculating the mathematical expectation. As on the CASF-2016 benchmark, PLANET v2.0 demonstrates excellent scoring power, ranking power, and docking power. The screening power of PLANET v2.0 gets notably improved compared to PLANET and Glide SP and it demonstrates robust validation on a commercial ultra-large-scale dataset. Given its efficiency and accuracy, PLANET v2.0 can hopefully become one of the practical tools for virtual screening workflows. PLANET v2.0 is freely available at https://www.pdbbind-plus.org.cn/planetv2.",
    "domain": "q-bio",
    "arxiv_id": "2601.07415v1",
    "score": 9
  },
  {
    "paper_id": 997,
    "title": "On Dual Connectivity in 6G Leo Constellations",
    "abstract": "Dual connectivity (DC) has garnered significant attention in 5G evolution, allowing for enhancing throughput and reliability by leveraging the channel conditions of two paths. However, when the paths exhibit different delays, such as in terrestrial and non-terrestrial integrated networks with multi-orbit topologies or in networks characterized by frequent topology changes, like Low Earth Orbit (LEO) satellite constellations with different elevation angles, traffic delivery may experience packet reordering or triggering congestion control mechanisms. Additionally, real-time traffic may experience packet drops if their arrival exceeds a play-out threshold. Different techniques have been proposed to address these issues, such as packet duplication, packet switching, and network coding for traffic scheduling in DC. However, if not accurately designed, these techniques can lead to resource waste, encoding/decoding delays, and computational overhead, undermining DC's intended benefits. This paper provides a mathematical framework for calculating the average end-to-end packet loss in case of a loss process modeled with a Discrete Markov Chain - typical of a wireless channel - when combining packet duplication and packet switching or when network coding is employed in DC. Such metrics help derive optimal policies with full knowledge of the underlying loss process to be compared to empirical models learned through Machine Learning algorithms.",
    "domain": "cs",
    "arxiv_id": "2602.04825v1",
    "score": 9
  },
  {
    "paper_id": 1008,
    "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning",
    "abstract": "Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \\textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.",
    "domain": "cs",
    "arxiv_id": "2602.05818v1",
    "score": 8
  },
  {
    "paper_id": 1098,
    "title": "Enabling Large-Scale Channel Sounding for 6G: A Framework for Sparse Sampling and Multipath Component Extraction",
    "abstract": "Realizing the 6G vision of artificial intelligence (AI) and integrated sensing and communication (ISAC) critically requires large-scale real-world channel datasets for channel modeling and data-driven AI models. However, traditional frequency-domain channel sounding methods suffer from low efficiency due to a prohibitive number of frequency points to avoid delay ambiguity. This paper proposes a novel channel sounding framework involving sparse nonuniform sampling along with a likelihood-rectified space-alternating generalized expectation-maximization (LR-SAGE) algorithm for multipath component extraction. This framework enables the acquisition of channel datasets that are tens or even hundreds of times larger within the same channel measurement duration, thereby providing the massive data required to harness the full potential of AI scaling laws. Specifically, we propose a Parabolic Frequency Sampling (PFS) strategy that non-uniformly distributes frequency points, effectively eliminating delay ambiguity while reducing sampling overhead by orders of magnitude. To efficiently extract multipath components (MPCs) from the channel data measured by PFS, we develop a LR-SAGE algorithm, rectifying the likelihood distortion caused by nonuniform sampling and molecular absorption effect. Simulation results and experimental validation at 280--300~GHz confirm that the proposed PFS and LR-SAGE algorithm not only achieve 50$\\times$ faster measurement, a 98\\% reduction in data volume and a 99.96\\% reduction in post-processing computational complexity, but also successfully captures MPCs and channel characteristics consistent with traditional exhaustive measurements, demonstrating its potential as a fundamental enabler for constructing the massive ISAC datasets required by AI-native 6G systems.",
    "domain": "cs",
    "arxiv_id": "2602.05405v1",
    "score": 8
  },
  {
    "paper_id": 1138,
    "title": "Mitigating GIL Bottlenecks in Edge AI Systems",
    "abstract": "Deploying Python-based AI agents on resource-constrained edge devices presents a critical runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread pool scaling causes a \"saturation cliff\": a performance degradation of >= 20% at overprovisioned thread counts (N >= 512) on edge representative configurations. We present a lightweight profiling tool and adaptive runtime system that uses a Blocking Ratio metric (beta) to distinguish genuine I/O wait from GIL contention. Our library-based solution achieves 96.5% of optimal performance without manual tuning, outperforming multiprocessing (which is limited by ~8x memory overhead on devices with 512 MB-2 GB RAM) and asyncio (which blocks during CPU bound phases). Evaluation across seven edge AI workload profiles, including real ML inference with ONNX Runtime MobileNetV2, demonstrates 93.9% average efficiency. Comparative experiments with Python 3.13t (free-threading) show that while GIL elimination enables ~4x throughput on multi-core edge devices, the saturation cliff persists on single-core devices due to context switching overhead, validating our beta metric for both GIL and no-GIL environments. This work provides a practical optimization strategy for memory-constrained edge AI systems where traditional solutions fail.",
    "domain": "cs",
    "arxiv_id": "2601.10582v2",
    "score": 8
  },
  {
    "paper_id": 1353,
    "title": "Restoring Sparsity in Potts Machines via Mean-Field Constraints",
    "abstract": "Ising machines and related probabilistic hardware have emerged as promising platforms for NP-hard optimization and sampling. However, many practical problems involve constraints that induce dense or all-to-all couplings, undermining scalability and hardware efficiency. We address this constraint-induced density through two complementary approaches. First, we introduce a hardware-aware native formulation for multi-state probabilistic digits (p-dits) that avoids the locally dense intra-variable couplings required by binary Ising encodings. We validate p-dit dynamics by reproducing known critical behavior of the 2D Potts model. Second, we propose mean-field constraints (MFC), a hybrid scheme that replaces dense pairwise constraint couplings with dynamically updated single-node biases. Applied to balanced graph partitioning, MFC achieves solution quality comparable to exact all-to-all constraint formulations while dramatically reducing graph density. Finally, we demonstrate the practical impact of restored sparsity by an FPGA implementation, enabling orders-of-magnitude acceleration over CPU-based solvers. Together, these results outline a pathway for scaling constrained optimization on probabilistic hardware.",
    "domain": "cs",
    "arxiv_id": "2602.04200v1",
    "score": 9
  },
  {
    "paper_id": 1375,
    "title": "ROMAN: Reward-Orchestrated Multi-Head Attention Network for Autonomous Driving System Testing",
    "abstract": "Automated Driving System (ADS) acts as the brain of autonomous vehicles, responsible for their safety and efficiency. Safe deployment requires thorough testing in diverse real-world scenarios and compliance with traffic laws like speed limits, signal obedience, and right-of-way rules. Violations like running red lights or speeding pose severe safety risks. However, current testing approaches face significant challenges: limited ability to generate complex and high-risk law-breaking scenarios, and failing to account for complex interactions involving multiple vehicles and critical situations. To address these challenges, we propose ROMAN, a novel scenario generation approach for ADS testing that combines a multi-head attention network with a traffic law weighting mechanism. ROMAN is designed to generate high-risk violation scenarios to enable more thorough and targeted ADS evaluation. The multi-head attention mechanism models interactions among vehicles, traffic signals, and other factors. The traffic law weighting mechanism implements a workflow that leverages an LLM-based risk weighting module to evaluate violations based on the two dimensions of severity and occurrence. We have evaluated ROMAN by testing the Baidu Apollo ADS within the CARLA simulation platform and conducting extensive experiments to measure its performance. Experimental results demonstrate that ROMAN surpassed state-of-the-art tools ABLE and LawBreaker by achieving 7.91% higher average violation count than ABLE and 55.96% higher than LawBreaker, while also maintaining greater scenario diversity. In addition, only ROMAN successfully generated violation scenarios for every clause of the input traffic laws, enabling it to identify more high-risk violations than existing approaches.",
    "domain": "cs",
    "arxiv_id": "2602.05629v1",
    "score": 8
  },
  {
    "paper_id": 1401,
    "title": "Constrained Dynamic Gaussian Splatting",
    "abstract": "While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.",
    "domain": "cs",
    "arxiv_id": "2602.03538v1",
    "score": 8
  },
  {
    "paper_id": 1417,
    "title": "TinyGuard:A lightweight Byzantine Defense for Resource-Constrained Federated Learning via Statistical Update Fingerprints",
    "abstract": "Existing Byzantine robust aggregation mechanisms typically rely on fulldimensional gradi ent comparisons or pairwise distance computations, resulting in computational overhead that limits applicability in large scale and resource constrained federated systems. This paper proposes TinyGuard, a lightweight Byzantine defense that augments the standard FedAvg algorithm via statistical update f ingerprinting. Instead of operating directly on high-dimensional gradients, TinyGuard extracts compact statistical fingerprints cap turing key behavioral properties of client updates, including norm statistics, layer-wise ratios, sparsity measures, and low-order mo ments. Byzantine clients are identified by measuring robust sta tistical deviations in this low-dimensional fingerprint space with nd complexity, without modifying the underlying optimization procedure. Extensive experiments on MNIST, Fashion-MNIST, ViT-Lite, and ViT-Small with LoRA adapters demonstrate that TinyGuard pre serves FedAvg convergence in benign settings and achieves up to 95 percent accuracy under multiple Byzantine attack scenarios, including sign-flipping, scaling, noise injection, and label poisoning. Against adaptive white-box adversaries, Pareto frontier analysis across four orders of magnitude confirms that attackers cannot simultaneously evade detection and achieve effective poisoning, features we term statistical handcuffs. Ablation studies validate stable detection precision 0.8 across varying client counts (50-150), threshold parameters and extreme data heterogeneity . The proposed framework is architecture-agnostic and well-suited for federated fine-tuning of foundation models where traditional Byzantine defenses become impractical",
    "domain": "cs",
    "arxiv_id": "2602.02615v1",
    "score": 8
  },
  {
    "paper_id": 1540,
    "title": "Optimal Learning-Rate Schedules under Functional Scaling Laws: Power Decay and Warmup-Stable-Decay",
    "abstract": "We study optimal learning-rate schedules (LRSs) under the functional scaling law (FSL) framework introduced in Li et al. (2025), which accurately models the loss dynamics of both linear regression and large language model (LLM) pre-training. Within FSL, loss dynamics are governed by two exponents: a source exponent $s>0$ controlling the rate of signal learning, and a capacity exponent $\u03b2>1$ determining the rate of noise forgetting. Focusing on a fixed training horizon $N$, we derive the optimal LRSs and reveal a sharp phase transition. In the easy-task regime $s \\ge 1 - 1/\u03b2$, the optimal schedule follows a power decay to zero, $\u03b7^*(z) = \u03b7_{\\mathrm{peak}}(1 - z/N)^{2\u03b2- 1}$, where the peak learning rate scales as $\u03b7_{\\mathrm{peak}} \\eqsim N^{-\u03bd}$ for an explicit exponent $\u03bd= \u03bd(s,\u03b2)$. In contrast, in the hard-task regime $s < 1 - 1/\u03b2$, the optimal LRS exhibits a warmup-stable-decay (WSD) (Hu et al. (2024)) structure: it maintains the largest admissible learning rate for most of training and decays only near the end, with the decay phase occupying a vanishing fraction of the horizon.\n  We further analyze optimal shape-fixed schedules, where only the peak learning rate is tuned -- a strategy widely adopted in practiceand characterize their strengths and intrinsic limitations. This yields a principled evaluation of commonly used schedules such as cosine and linear decay. Finally, we apply the power-decay LRS to one-pass stochastic gradient descent (SGD) for kernel regression and show the last iterate attains the exact minimax-optimal rate, eliminating the logarithmic suboptimality present in prior analyses. Numerical experiments corroborate our theoretical predictions.",
    "domain": "stat",
    "arxiv_id": "2602.06797v1",
    "score": 9
  },
  {
    "paper_id": 1565,
    "title": "AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models",
    "abstract": "Reinforcement learning from human feedback (RLHF) shows promise for aligning diffusion and flow models, yet policy optimization methods such as GRPO suffer from inefficient and static sampling strategies. These methods treat all prompts and denoising steps uniformly, ignoring substantial variations in sample learning value as well as the dynamic nature of critical exploration moments.\n  To address this issue, we conduct a detailed analysis of the internal attention dynamics during GRPO training and uncover a key insight: attention entropy can serve as a powerful dual-signal proxy. First, across different samples, the relative change in attention entropy (\u0394Entropy), which reflects the divergence between the current policy and the base policy, acts as a robust indicator of sample learning value. Second, during the denoising process, the peaks of absolute attention entropy (Entropy(t)), which quantify attention dispersion, effectively identify critical timesteps where high-value exploration occurs.\n  Building on this observation, we propose Adaptive Entropy-Guided Policy Optimization (AEGPO), a novel dual-signal, dual-level adaptive optimization strategy. At the global level, AEGPO uses \u0394Entropy to dynamically allocate rollout budgets, prioritizing prompts with higher learning value. At the local level, it exploits the peaks of Entropy(t) to guide exploration selectively at critical high-dispersion timesteps rather than uniformly across all denoising steps.\n  By focusing computation on the most informative samples and the most critical moments, AEGPO enables more efficient and effective policy optimization. Experiments on text-to-image generation tasks demonstrate that AEGPO significantly accelerates convergence and achieves superior alignment performance compared to standard GRPO variants.",
    "domain": "cs",
    "arxiv_id": "2602.06825v1",
    "score": 9
  },
  {
    "paper_id": 1629,
    "title": "Optimal Control Strategies for Epidemic Dynamics: Integrating SIR-SI and Lotka--Volterra Models",
    "abstract": "In this work we present a mathematical model that integrates the epidemiological dynamics of a vector-borne disease (SIR-SI) with Lotka Volterra predator prey ecological interactions. The study analyzes how the presence of natural predators acts as a biological control mechanism to regulate the vector population and, consequently, disease transmission in host. \nWe introduce the concept of the ecological reproduction number, a threshold that links the amplitude of predator prey cycles to disease persistence, showing that natural control depends critically on the ratio between the maximum vector density and the minimum predator density. In scenarios where natural control is insufficient, we formulate an optimal control problem based on the release of predators. Using the Pontryagin Maximum Principle, we characterize the optimal strategy that minimizes the cumulative number of infected individuals and intervention costs, while simultaneously maximizing the susceptible host population at the end of the time horizon. Numerical simulations validate the effectiveness of the model, showing that external intervention mitigates the epidemic peak and stabilizes the system against the natural oscillations of biological populations.",
    "domain": "math",
    "arxiv_id": "2602.06178v1",
    "score": 9
  },
  {
    "paper_id": 1744,
    "title": "Improve Large Language Model Systems with User Logs",
    "abstract": "Scaling training data and model parameters has long driven progress in large language models (LLMs), but this paradigm is increasingly constrained by the scarcity of high-quality data and diminishing returns from rising computational costs. As a result, recent work is increasing the focus on continual learning from real-world deployment, where user interaction logs provide a rich source of authentic human feedback and procedural knowledge. However, learning from user logs is challenging due to their unstructured and noisy nature. Vanilla LLM systems often struggle to distinguish useful feedback signals from noisy user behavior, and the disparity between user log collection and model optimization (e.g., the off-policy optimization problem) further strengthens the problem. To this end, we propose UNO (User log-driveN Optimization), a unified framework for improving LLM systems (LLMsys) with user logs. UNO first distills logs into semi-structured rules and preference pairs, then employs query-and-feedback-driven clustering to manage data heterogeneity, and finally quantifies the cognitive gap between the model's prior knowledge and the log data. This assessment guides the LLMsys to adaptively filter out noisy feedback and construct different modules for primary and reflective experiences extracted from user logs, thereby improving future responses. Extensive experiments show that UNO achieves state-of-the-art effectiveness and efficiency, significantly outperforming Retrieval Augmented Generation (RAG) and memory-based baselines. We have open-sourced our code at https://github.com/bebr2/UNO .",
    "domain": "cs",
    "arxiv_id": "2602.06470v1",
    "score": 9
  },
  {
    "paper_id": 1985,
    "title": "Convex Hull 3D Filtering with GPU Ray Tracing and Tensor Cores",
    "abstract": "In recent years, applications such as real-time simulations, autonomous systems, and video games increasingly demand the processing of complex geometric models under stringent time constraints. Traditional geometric algorithms, including the convex hull, are subject to these challenges. A common approach to improve performance is scaling computational resources, which often results in higher energy consumption. Given the growing global concern regarding sustainable use of energy, this becomes a critical limitation. This work presents a 3D preprocessing filter for the convex hull algorithm using ray tracing and tensor core technologies. The filter builds a delimiter polyhedron based on Manhattan distances that discards points from the original set. The filter is evaluated on two point distributions: uniform and sphere. Experimental results show that the proposed filter, combined with convex hull construction, accelerates the computation of the 3D convex hull by up to 200x with respect to a CPU parallel implementation. This research demonstrates that geometric algorithms can be accelerated through massive parallelism while maintaining efficient energy utilization. Beyond execution time and speedup evaluation, we also analyze GPU energy consumption, showing that the proposed preprocessing filter not only reduces the computational workload but also achieves performance gains with controlled energy usage. These results highlight the dual benefit of the method in terms of both speed and energy efficiency, reinforcing its applicability in modern high-performance scenarios.",
    "domain": "cs",
    "arxiv_id": "2601.19647v2",
    "score": 9
  },
  {
    "paper_id": 2068,
    "title": "Impulsive Release Strategies for Wolbachia-Infected Mosquitoes under Temperature-Induced Infection Loss",
    "abstract": "The release of Wolbachia-infected mosquitoes is a promising strategy for controlling Aedes aegypti populations, but exposure to high temperatures can induce temporary infection loss and compromise long-term persistence. In this work, we propose a population-dynamics model based on impulsive differential equations to describe the interaction between wild and infected mosquitoes, incorporating cytoplasmic incompatibility, periodic release interventions, and temperature-driven infection loss. Analytical threshold conditions are derived to characterize the existence and stability of periodic solutions associated with successful Wolbachia establishment. Numerical simulations illustrate the theoretical results and enable a comparative analysis of the wMelPop, wMel, and wAlbB strains, highlighting how differences in thermal tolerance and fitness costs influence persistence after the release phase. The results emphasize the importance of accounting for environmental stress and impulsive interventions when designing effective and robust Wolbachia release strategies.",
    "domain": "q-bio",
    "arxiv_id": "2602.07231v1",
    "score": 9
  },
  {
    "paper_id": 2105,
    "title": "Hybrid Responsible AI-Stochastic Approach for SLA Compliance in Multivendor 6G Networks",
    "abstract": "The convergence of AI and 6G network automation introduces new challenges in maintaining transparency, fairness, and accountability across multivendor management systems. Although closed-loop AI orchestration improves adaptability and self-optimization, it also creates a responsibility gap, where violations of SLAs cannot be causally attributed to specific agents or vendors. This paper presents a hybrid responsible AI-stochastic learning framework that embeds fairness, robustness, and auditability directly into the network control loop. The framework integrates RAI games with stochastic optimization, enabling dynamic adversarial reweighting and probabilistic exploration across heterogeneous vendor domains. An RAAP continuously records AI-driven decision trajectories and produces dual accountability reports: user-level SLA summaries and operator-level responsibility analytics. Experimental evaluations on synthetic two-class multigroup datasets demonstrate that the proposed hybrid model improves the accuracy of the worst group by up to 10.5\\%. Specifically, hybrid RAI achieved a WGAcc of 60.5\\% and an AvgAcc of 72.7\\%, outperforming traditional RAI-GA (50.0\\%) and ERM (21.5\\%). The audit mechanism successfully traced 99\\% simulated SLA violations to the AI entities responsible, producing both vendor and agent-level accountability indices. These results confirm that the proposed hybrid approach enhances fairness and robustness as well as establishes a concrete accountability framework for autonomous SLA assurance in multivendor 6G networks.",
    "domain": "cs",
    "arxiv_id": "2602.09841v1",
    "score": 8
  },
  {
    "paper_id": 2139,
    "title": "AbFlow : End-to-end Paratope-Centric Antibody Design by Interaction Enhanced Flow Matching",
    "abstract": "Antigen-antibody binding is a critical process in the immune response. Although recent progress has advanced antibody design, current methods lack a generative framework for end-to-end modeling of full-atom antibody structures and struggle to fully exploit antigen-specific geometric information for optimizing local binding interfaces and global structures. To overcome these limitations, we introduce AbFlow, a flow-matching framework that leverages optimal transport to design full-atom antibodies end-to-end. AbFlow incorporates an extended velocity field network featuring an equivariant Surface Multi-channel Encoder, which uses surface-level antigen interaction data to refine the antibody structure, particularly the CDR-H3 region. Extensive experiments in paratoep-centric antibody design, multi-CDRs and full-atom antibody design, binding affinity optimization, and complex structure prediction show that AbFlow produces superior antigen-antibody complexes, especially at the contact interface, and markedly improves the binding affinity of generated antibodies.",
    "domain": "q-bio",
    "arxiv_id": "2602.07084v1",
    "score": 8
  },
  {
    "paper_id": 2170,
    "title": "The Architecture of Illusion: Network Opacity and Strategic Escalation",
    "abstract": "Standard models of bounded rationality typically assume agents either possess accurate knowledge of the population's reasoning abilities (Cognitive Hierarchy) or hold dogmatic, degenerate beliefs (Level-$k$). We introduce the ``Connected Minds'' model, which unifies these frameworks by integrating iterative reasoning with a parameterized network bias. We posit that agents do not observe the global population; rather, they observe a sample biased by their network position, governed by a locality parameter $p$ representing algorithmic ranking, social homophily, or information disclosure. We show that this parameter acts as a continuous bridge: the model collapses to the myopic Level-$k$ recursion as networks become opaque ($p \\to 0$) and recovers the standard Cognitive Hierarchy model under full transparency ($p=1$). Theoretically, we establish that network opacity induces a \\emph{Sophisticated Bias}, causing agents to systematically overestimate the cognitive depth of their opponents while preserving the log-concavity of belief distributions. This makes $p$ an actionable lever: a planner or platform can tune transparency -- globally or by segment (a personalized $p_k$) -- to shape equilibrium behavior. From a mechanism design perspective, we derive the \\emph{Escalation Principle}: in games of strategic complements, restricting information can maximize aggregate effort by trapping agents in echo chambers where they compete against hallucinated, high-sophistication peers. Conversely, we identify a \\emph{Transparency Reversal} for coordination games, where maximizing network visibility is required to minimize variance and stabilize outcomes. Our results suggest that network topology functions as a cognitive zoom lens, determining whether agents behave as local imitators or global optimizers.",
    "domain": "cs",
    "arxiv_id": "2602.10053v1",
    "score": 8
  },
  {
    "paper_id": 2194,
    "title": "Emergence of Superintelligence from Collective Near-Critical Dynamics in Reentrant Neural Fields",
    "abstract": "Superintelligence is commonly envisioned as a quantitative extrapolation of human cognitive abilities driven by scale and computational power. Here we show that qualitative transitions in intelligence instead arise as dynamical phase transitions governed by collective critical dynamics. Building on a unified dynamical field-theoretic framework for cognition, we demonstrate that progressive collective coupling generated by reentrant mixing drives the system toward an infrared critical regime in which an extensive band of slow collective modes emerges. This spectral condensation reorganizes cognitive dynamics from localized relaxation to coherent motion along emergent low-dimensional manifolds. Through numerical analysis of the time-scale density of states, we identify robust power-law scaling of collective relaxation rates with well-defined critical exponents, placing the system within the universality class of self-organized critical many-body dynamics. Criticality alone would generically lead to instability. We further show that homeostatic regulation introduces a gapped stabilizing direction that protects the collective critical sector, yielding a dynamically maintained meta-stable infrared phase in which long-lived inference trajectories persist without collapse. The coexistence of scale-free collective dynamics and global stabilization defines a protected sector-critical regime in which coherence and internal flexibility coexist. Superintelligence therefore corresponds to a distinct dynamical stability class--a self-organized critical phase embedded within a stabilized cognitive manifold--rather than a smooth quantitative continuation of existing cognitive systems.",
    "domain": "physics",
    "arxiv_id": "2602.08483v1",
    "score": 8
  }
]