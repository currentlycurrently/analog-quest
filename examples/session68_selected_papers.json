{
  "session": 68,
  "total_papers": 50,
  "score_filter": 7,
  "papers": [
    {
      "paper_id": 489,
      "domain": "physics",
      "subdomain": "physics.comp-ph",
      "title": "Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS",
      "arxiv_id": "2602.02234v1",
      "score": 7.0,
      "abstract": "State-of-the-art AI deep potentials provide ab initio-quality results, but at a fraction of the computational cost of first-principles quantum mechanical calculations, such as density functional theory. In this work, we bring AI deep potentials into GROMACS, a production-level Molecular Dynamics (MD) code, by integrating with DeePMD-kit that provides domain-specific deep learning (DL) models of interatomic potential energy and force fields. In particular, we enable AI deep potentials inference across multiple DP model families and DL backends by coupling GROMACS Neural Network Potentials with the C++/CUDA backend in DeePMD-kit. We evaluate two recent large-atom-model architectures, DPA2 that is based on the attention mechanism and DPA3 that is based on GNN, in GROMACS using four ab initio-quality protein-in-water benchmarks (1YRF, 1UBQ, 3LZM, 2PTC) on NVIDIA A100 and GH200 GPUs. Our results show that DPA2 delivers up to 4.23x and 3.18x higher throughput than DPA3 on A100 and GH200 GPUs, respectively. We also provide a characterization study to further contrast DPA2 and DPA3 in throughput, memory usage, and kernel-level execution on GPUs. Our findings identify kernel-launch overhead and domain-decomposed inference as the main optimization priorities for AI deep potentials in production MD simulations."
    },
    {
      "paper_id": 524,
      "domain": "q-bio",
      "subdomain": "q-bio.CB",
      "title": "A novel scalable high performance diffusion solver for multiscale cell simulations",
      "arxiv_id": "2602.05017v1",
      "score": 7.0,
      "abstract": "Agent-based cellular models simulate tissue evolution by capturing the behavior of individual cells, their interactions with neighboring cells, and their responses to the surrounding microenvironment. An important challenge in the field is scaling cellular resolution models to real-scale tumor simulations, which is critical for the development of digital twin models of diseases and requires the use of High-Performance Computing (HPC) since every time step involves trillions of operations. We hereby present a scalable HPC solution for the molecular diffusion modeling using an efficient implementation of state-of-the-art Finite Volume Method (FVM) frameworks. The paper systematically evaluates a novel scalable Biological Finite Volume Method (BioFVM) library and presents an extensive performance analysis of the available solutions. Results shows that our HPC proposal reach almost 200x speedup and up to 36% reduction in memory usage over the current state-of-the-art solutions, paving the way to efficiently compute the next generation of biological problems."
    },
    {
      "paper_id": 603,
      "domain": "cs",
      "subdomain": "cs.CR",
      "title": "Time-Complexity Characterization of NIST Lightweight Cryptography Finalists",
      "arxiv_id": "2602.05641v1",
      "score": 7.0,
      "abstract": "Lightweight cryptography is becoming essential as emerging technologies in digital identity systems and Internet of Things verification continue to demand strong cryptographic assurance on devices with limited processing power, memory, and energy resources. As these technologies move into routine use, they demand cryptographic primitives that maintain strong security and deliver predictable performance through clear theoretical models of time complexity. Although NIST's lightweight cryptography project provides empirical evaluations of the ten finalist algorithms, a unified theoretical understanding of their time-complexity behavior remains absent. This work introduces a symbolic model that decomposes each scheme into initialization, data-processing, and finalization phases, enabling formal time-complexity derivation for all ten finalists. The results clarify how design parameters shape computational scaling on constrained mobile and embedded environments. The framework provides a foundation needed to distinguish algorithmic efficiency and guides the choice of primitives capable of supporting security systems in constrained environments."
    },
    {
      "paper_id": 650,
      "domain": "physics",
      "subdomain": "physics.chem-ph",
      "title": "Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics",
      "arxiv_id": "2602.04975v1",
      "score": 7.0,
      "abstract": "This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks."
    },
    {
      "paper_id": 696,
      "domain": "physics",
      "subdomain": "physics.plasm-ph",
      "title": "Improved Fluid Modeling of Space Debris Generated Ion-Acoustic Precursor Solitons",
      "arxiv_id": "2602.04338v1",
      "score": 7.0,
      "abstract": "This study reexamines the excitation of ion-acoustic precursor solitons by a supersonically moving charged debris object, incorporating two previously overlooked physical factors: the dynamic charging of the debris and the impermeable nature of its surface. The influence of charging dynamics is explored using an enhanced one-dimensional fluid-Poisson model, where the source charge is treated as a dynamical variable and solved self-consistently alongside the core plasma equations. By comparing these results with prior fixed-charge models, we evaluate the effects on soliton onset and propagation, finding that charging dynamics does not hinder soliton generation or evolution. To assess the impact of the impermeability of debris surface, a two-dimensional fluid model simulates the interaction between an electrostatically biased, impenetrable object and a flowing plasma. Modeling the object as an infinite wall disconnects the upstream and downstream plasma regions, forming a sheath without solitons -- consistent with earlier fluid and particle-in-cell simulations. However, replacing the wall with a finite object enables plasma flow around it, restoring upstream-downstream connectivity and naturally generating precursor solitons."
    },
    {
      "paper_id": 701,
      "domain": "physics",
      "subdomain": "physics.plasm-ph",
      "title": "Collisionless Larmor Coupling and Blob Formation in a Laser-Plasma Expanding into a Magnetized Ambient Plasma",
      "arxiv_id": "2602.03494v1",
      "score": 7.0,
      "abstract": "Collisionless Larmor coupling is a fundamental process in space and astrophysical plasmas that enables momentum transfer between an expanding plasma and a magnetized ambient medium. In this paper, we report on the laboratory experimental study of Larmor coupling leading to the formation of a plasma blob associated with a laser-driven, super-Alfv\u00e9nic plasma flow on the Large Plasma Device at the University of California, Los Angeles. The high-repetition rate enables systematic spatial and temporal scans of the plasma evolution using Doppler spectroscopy, as well as measurements of the magnetic field, electrostatic field, and self-emission of both debris and ambient ions using filtered imaging. We observe the self-focusing of the laser-produced plasma and the formation of a secondary diamagnetic cavity associated with a blob composed of background ions. Doppler spectroscopy reveals the transverse velocity distribution of the background ions, providing direct evidence of ion energization via Larmor coupling. The systematic spatial and temporal scans enabled by the high-repetition rate experiment allow for a detailed characterization of the ion dynamics. These experimental observations are supported by numerical simulations that provide more insight into the kinetic-scale physics associated with blob formation as well as the role of the ambient plasma density."
    },
    {
      "paper_id": 747,
      "domain": "math",
      "subdomain": "math.NA",
      "title": "Towards uncertainty quantification of a model for cancer-on-chip experiments",
      "arxiv_id": "2602.06018v1",
      "score": 7.0,
      "abstract": "This study is a first step towards using data-informed differential models to predict and control the dynamics of cancer-on-chip experiments. We consider a conceptualized one-dimensional device, containing a cancer and a population of white blood cells. The interaction between the cancer and the population of cells is modeled by a chemotaxis model inspired by Keller-Segel-type equations, which is solved by a Hybridized Discontinuous Galerkin method. Our goal is using (synthetic) data to tune the parameters of the governing equations and to assess the uncertainty on the predictions of the dynamics due to the residual uncertainty on the parameters remaining after the tuning procedure. To this end, we apply techniques from uncertainty quantification for parametric differential models. We first perform a global sensitivity analysis using both Sobol and Morris indices to assess how parameter uncertainty impacts model predictions, and fix the value of parameters with negligible impact. Subsequently, we conduct an inverse uncertainty quantification analysis by Bayesian techniques to compute a data-informed probability distribution of the remaining model parameters. Finally, we carry out a forward uncertainty quantification analysis to compute the impact of the updated (residual) parametric uncertainties on the quantities of interest of the model. The whole procedure is sped up by using surrogate models, based on sparse-grids, to approximate the mapping of the uncertain parameters to the quantities of interest."
    },
    {
      "paper_id": 785,
      "domain": "physics",
      "subdomain": "physics.ao-ph",
      "title": "Radar-Based Raindrop Size Distribution Prediction: Comparing Analytical, Neural Network, and Decision Tree Approaches",
      "arxiv_id": "2602.01236v1",
      "score": 7.0,
      "abstract": "Reliable estimation of the raindrop size distribution (RSD) is important for applications including quantitative precipitation estimation, soil erosion modelling, and wind turbine blade erosion. While in situ instruments such as disdrometers provide detailed RSD measurements, they are spatially limited, motivating the use of polarimetric radar for remote retrieval of rain microphysical properties. This study presents a comparative evaluation of analytical and machine-learning approaches for retrieving RSD parameters from polarimetric radar observables. One-minute OTT Parsivel2 disdrometer measurements collected between September 2020 and May 2022 at Sheepdrove Farm, UK, were quality-controlled using collocated weighing and tipping-bucket rain gauges. Measured RSDs were fitted to a normalised three-parameter gamma distribution, from which a range of polarimetric radar variables were analytically simulated. Analytical retrievals, neural networks, and decision tree models were then trained to estimate the gamma distribution parameters across multiple radar feature sets and model architectures. To assess robustness and equifinality, each model configuration was trained 100 times using random 70/30 train-test splits, yielding approximately 17,000 trained models in total. Machine-learning approaches generally outperform analytical methods; however, no single model class or architecture is uniformly optimal. Model performance depends strongly on both the target RSD parameter and the available radar observables, with decision trees showing particular robustness in reduced-feature regimes. These results highlight the importance of aligning retrieval model structure with operational data constraints rather than adopting a single universal approach."
    },
    {
      "paper_id": 787,
      "domain": "physics",
      "subdomain": "physics.ao-ph",
      "title": "HybridOM: Hybrid Physics-Based and Data-Driven Global Ocean Modeling with Efficient Spatial Downscaling",
      "arxiv_id": "2602.00598v1",
      "score": 7.0,
      "abstract": "Global ocean modeling is vital for climate science but struggles to balance computational efficiency with accuracy. Traditional numerical solvers are accurate but computationally expensive, while pure deep learning approaches, though fast, often lack physical consistency and long-term stability. To address this, we introduce HybridOM, a framework integrating a lightweight, differentiable numerical solver as a skeleton to enforce physical laws, with a neural network as the flesh to correct subgrid-scale dynamics. To enable efficient high-resolution modeling, we further introduce a physics-informed regional downscaling mechanism based on flux gating. This design achieves the inference efficiency of AI-based methods while preserving the accuracy and robustness of physical models. Extensive experiments on the GLORYS12V1 and OceanBench dataset validate HybridOM's performance in two distinct regimes: long-term subseasonal-to-seasonal simulation and short-term operational forecasting coupled with the FuXi-2.0 weather model. Results demonstrate that HybridOM achieves state-of-the-art accuracy while strictly maintaining physical consistency, offering a robust solution for next-generation ocean digital twins. Our source code is available at https://github.com/ChiyodaMomo01/HybridOM."
    },
    {
      "paper_id": 802,
      "domain": "q-bio",
      "subdomain": "q-bio.SC",
      "title": "Comment on \"Repair of DNA Double-Strand Breaks Leaves Heritable Impairment to Genome Function\"",
      "arxiv_id": "2511.11986v2",
      "score": 7.0,
      "abstract": "Bantele and colleagues recently reported that repair of a single CRISPR/Cas9-induced DNA double-strand break (DSB) in the c-MYC topologically associated domain leads to a persistent depletion of chromatin interactions and long-term transcriptional attenuation across multiple generations of human cells. They interpret this observation as evidence for a previously unrecognized principle--\"chromatin fatigue\"--in which DSB repair generates a stable architectural defect that acts as a heritable impairment to genome function. Such an idea, if correct, would carry profound implications for genome biology, epigenetic inheritance, cancer evolution, aging, and the safety of therapeutic genome editing. However, our detailed reassessment of the experimental design, underlying assumptions, and data interpretation reveals that the evidence provided is inadequate to support these sweeping conclusions. Instead, the observed outcomes are more plausibly explained by a combination of Cas9 persistence, off-target DNA damage, repair-factor retention, MYC enhancer plasticity, and the well-documented genomic instability of HeLa cells. The study does not demonstrate mechanistic causality, does not exclude simpler explanations, and does not provide data consistent with true chromatin memory or heritable architectural change. Moreover, its statistical inferences are based on noisy measurements that fall within expected variability of unstable oncogenic loci. Here, we present a comprehensive critical analysis showing that the proposed model of chromatin fatigue is unsupported by the available evidence. We offer a corrected interpretation in which the chromatin landscape experiences a temporary, repair-associated perturbation that resolves without leaving enduring or heritable impairment."
    },
    {
      "paper_id": 998,
      "domain": "cs",
      "subdomain": "cs.NI",
      "title": "LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks",
      "arxiv_id": "2602.04471v1",
      "score": 7.0,
      "abstract": "This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme."
    },
    {
      "paper_id": 1003,
      "domain": "cs",
      "subdomain": "cs.NI",
      "title": "xDevSM: An Open-Source Framework for Portable, AI-Ready xApps Across Heterogeneous O-RAN Deployments",
      "arxiv_id": "2602.03821v1",
      "score": 7.0,
      "abstract": "Openness and programmability in the O-RAN architecture enable closed-loop control of the Radio Access Network (RAN). Artificial Intelligence (AI)-driven xApps, in the near-real-time RAN Intelligent Controller (RIC), can learn from network data, anticipate future conditions, and dynamically adapt radio configurations. However, their development and adoption are hindered by the complexity of low-level RAN control and monitoring message models exposed over the O-RAN E2 interface, limited interoperability across heterogeneous RAN software stacks, and the lack of developer-friendly frameworks. In this paper, we introduce xDevSM, a framework that significantly lowers the barrier to xApp development by unifying observability and control in O-RAN deployment. By exposing a rich set of Key Performance Measurements (KPMs) and enabling fine-grained radio resource management controls, xDevSM provides the essential foundation for practical AI-driven xApps. We validate xDevSM on real-world testbeds, leveraging Commercial Off-the-Shelf (COTS) devices together with heterogeneous RAN hardware, including Universal Software Radio Peripheral (USRP)-based Software-defined Radios (SDRs) and Foxconn radio units, and show its seamless interoperability across multiple open-source RAN software stacks. Furthermore, we discuss and evaluate the capabilities of our framework through three O-RAN-based scenarios of high interest: (i) KPM-based monitoring of network performance, (ii) slice-level Physical Resource Block (PRB) allocation control across multiple User Equipments (UEs) and slices, and (iii) mobility-aware handover control, showing that xDevSM can implement intelligent closed-loop applications, laying the groundwork for learning-based optimization in heterogeneous RAN deployments. xDevSM is open source and available as foundational tool for the research community."
    },
    {
      "paper_id": 1005,
      "domain": "cs",
      "subdomain": "cs.NI",
      "title": "Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model",
      "arxiv_id": "2602.03529v1",
      "score": 7.0,
      "abstract": "Video streaming is a fundamental Internet service, while the quality still cannot be guaranteed especially in poor network conditions such as bandwidth-constrained and remote areas. Existing works mainly work towards two directions: traditional pixel-codec streaming nearly approaches its limit and is hard to step further in compression; the emerging neural-enhanced or generative streaming usually fall short in latency and visual fidelity, hindering their practical deployment. Inspired by the recent success of vision foundation model (VFM), we strive to harness the powerful video understanding and processing capacities of VFM to achieve generalization, high fidelity and loss resilience for real-time video streaming with even higher compression rate. We present the first revolutionized paradigm that enables VFM-based end-to-end generative video streaming towards this goal. Specifically, Morphe employs joint training of visual tokenizers and variable-resolution spatiotemporal optimization under simulated network constraints. Additionally, a robust streaming system is constructed that leverages intelligent packet dropping to resist real-world network perturbations. Extensive evaluation demonstrates that Morphe achieves comparable visual quality while saving 62.5\\% bandwidth compared to H.265, and accomplishes real-time, loss-resilient video delivery in challenging network environments, representing a milestone in VFM-enabled multimedia streaming solutions."
    },
    {
      "paper_id": 1023,
      "domain": "cs",
      "subdomain": "cs.PL",
      "title": "Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs",
      "arxiv_id": "2602.03588v1",
      "score": 7.0,
      "abstract": "In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite domain $D$ that encompasses all possible values for each variable. The objective is to assign a value to each variable in such a way that all constraints are satisfied. In the graph variant of CSP, an underlying graph is considered and we have one variable corresponding to each vertex of the graph and one or several constraints corresponding to each edge. In PCSPs, we allow for certain constraints to be violated at a specified cost, aiming to find a solution that minimizes the total cost. Numerous classical compiler optimization tasks can be framed as PCSPs over control-flow graphs. Examples include Register Allocation, Lifetime-optimal Speculative Partial Redundancy Elimination (LOSPRE), and Optimal Placement of Bank Selection Instructions. On the other hand, it is well-known that control-flow graphs of structured programs are sparse and decomposable in a variety of ways. In this work, we rely on the Series-Parallel-Loop (SPL) decompositions as introduced by~\\cite{RegisterAllocation}. Our main contribution is a general algorithm for PCSPs over SPL graphs with a time complexity of \\(O(|G| \\cdot |D|^6)\\), where \\(|G|\\) represents the size of the control-flow graph. Note that for any fixed domain $D,$ this yields a linear-time solution. Our algorithm can be seen as a generalization and unification of previous SPL-based approaches for register allocation and LOSPRE. In addition, we provide experimental results over another classical PCSP task, i.e. Optimal Bank Selection, achieving runtimes four times better than the previous state of the art."
    },
    {
      "paper_id": 1025,
      "domain": "cs",
      "subdomain": "cs.PL",
      "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation",
      "arxiv_id": "2602.01935v1",
      "score": 7.0,
      "abstract": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models."
    },
    {
      "paper_id": 1068,
      "domain": "physics",
      "subdomain": "physics.med-ph",
      "title": "Accelerated Electromagnetic Simulation of MRI RF Interactions with Graphene Microtransistor-Based Neural Probes for Electrophysiology-fMRI Integration",
      "arxiv_id": "2602.03437v1",
      "score": 7.0,
      "abstract": "Implementing electrophysiological recordings within an MRI environment is challenging due to complex interactions between recording probes and MRI-generated fields, which can affect both safety and data quality. This study aims to develop and evaluate a hybrid electromagnetic (EM) simulation framework for efficient and accurate assessment of such interactions. Methods: A hybrid EM strategy integrating the Huygens' Box (HB) method with sub-gridding was implemented in an FDTD solver (Sim4Life). RF coil models for mouse and rat head were simulated with and without intracortical (IC) and epicortical (EC) graphene-based micro-transistor arrays. Three-dimensional multi-layered probe models were reconstructed from two-dimensional layouts, and transmit field ($B_{1}^{+}$), electric field ($E$), and specific absorption rate (SAR) distributions were evaluated. Performance was benchmarked against conventional full-wave multi-port (MP) simulations using Bland-Altman analysis and voxel-wise percentage differences. Results: HB simulations reduced computational time by approximately 70-80%, while preserving spatial patterns of $|B_{1}^{+}|$, $|E|$, and SAR, including transmit-field symmetry and localized high-field regions. Deviations from MP were minimal for $|B_{1}^{+}|$ (median $\u0394$% 0.02-0.07% in mice, -3.7% to -1.7% in rats) and modest for $|E|$ and SAR, with absolute SAR values remaining well below human safety limits. Graphene-based arrays produced negligible effects on RF transmission and SAR deposition. Conclusion: The HB approach enables computationally efficient, high-resolution evaluation of EM interactions involving microscopic probes in MRI environments, supporting simulations that are otherwise impractical with full-wave MP modeling."
    },
    {
      "paper_id": 1069,
      "domain": "physics",
      "subdomain": "physics.med-ph",
      "title": "Multiparameter Uncertainty Mapping in Quantitative Molecular MRI using a Physics-Structured Variational Autoencoder (PS-VAE)",
      "arxiv_id": "2602.03317v1",
      "score": 7.0,
      "abstract": "Quantitative imaging methods, such as magnetic resonance fingerprinting (MRF), aim to extract interpretable pathology biomarkers by estimating biophysical tissue parameters from signal evolutions. However, the pattern-matching algorithms or neural networks used in such inverse problems often lack principled uncertainty quantification, which limits the trustworthiness and transparency, required for clinical acceptance. Here, we describe a physics-structured variational autoencoder (PS-VAE) designed for rapid extraction of voxelwise multi-parameter posterior distributions. Our approach integrates a differentiable spin physics simulator with self-supervised learning, and provides a full covariance that captures the inter-parameter correlations of the latent biophysical space. The method was validated in a multi-proton pool chemical exchange saturation transfer (CEST) and semisolid magnetization transfer (MT) molecular MRF study, across in-vitro phantoms, tumor-bearing mice, healthy human volunteers, and a subject with glioblastoma. The resulting multi-parametric posteriors are in good agreement with those calculated using a brute-force Bayesian analysis, while providing an orders-of-magnitude acceleration in whole brain quantification. In addition, we demonstrate how monitoring the multi-parameter posterior dynamics across progressively acquired signals provides practical insights for protocol optimization and may facilitate real-time adaptive acquisition."
    },
    {
      "paper_id": 1100,
      "domain": "cs",
      "subdomain": "cs.IT",
      "title": "Integrated Sensing, Communication, and Control for UAV-Assisted Mobile Target Tracking",
      "arxiv_id": "2602.05209v1",
      "score": 7.0,
      "abstract": "Unmanned aerial vehicles (UAVs) are increasingly deployed in mission-critical applications such as target tracking, where they must simultaneously sense dynamic environments, ensure reliable communication, and achieve precise control. A key challenge here is to jointly guarantee tracking accuracy, communication reliability, and control stability within a unified framework. To address this issue, we propose an integrated sensing, communication, and control (ISCC) framework for UAV-assisted target tracking, where the considered tracking system is modeled as a discrete-time linear control process, with the objective of driving the deviation between the UAV and target states toward zero. We formulate a stochastic model predictive control (MPC) optimization problem for joint control and beamforming design, which is highly non-convex and intractable in its original form. To overcome this difficulty, the target state is first estimated using an extended Kalman filter (EKF). Then, by deriving the closed-form optimal beamforming solution under a given control input, the original problem is equivalently reformulated into a tractable control-oriented form. Finally, we convexify the remaining non-convex constraints via a relaxation-based convex approximation, yielding a computationally tractable convex optimization problem that admits efficient global solution. Numerical results show that the proposed ISCC framework achieves tracking accuracy comparable to a non-causal benchmark while maintaining stable communication, and it significantly outperforms the conventional control and tracking method."
    },
    {
      "paper_id": 1147,
      "domain": "cs",
      "subdomain": "cs.AR",
      "title": "System-Level Isolation for Mixed-Criticality RISC-V SoCs: A \"World\" Reality Check",
      "arxiv_id": "2602.05002v1",
      "score": 7.0,
      "abstract": "As RISC-V adoption accelerates, domains such as automotive, the Internet of Things (IoT), and industrial control are attracting growing attention. These domains are subject to stringent Size, Weight, Power, and Cost (SWaP-C) constraints, which have driven a shift toward heterogeneous Systems-on-Chip (SoCs) integrating general-purpose CPUs, tightly coupled accelerators, and diverse I/O devices with different integrity levels. While such integration improves cost efficiency and performance, it introduces a fundamental safety and security challenge: enforcing system-level isolation in mixed-criticality environments. Although RISC-V International has proposed several hardware isolation primitives, including RISC-V Worlds, IOPMP, and SmMTT, their interoperability, scalability, and suitability for real-time systems remain insufficiently understood. In this paper, we present a comparative analysis of these primitives from the perspective of practical heterogeneous SoC designs. We implement an IOPMP, a World-based checker, and a modified RISC-V World checker that addresses key limitations of the baseline specification, and evaluate their trade-offs in terms of security guarantees and power-performance-area (PPA). Our results show that the World-based checker introduces a fixed, configuration-independent access latency, achieving lower worst-case delay than the evaluated alternatives while scaling predictably with system size. At the macro level, we estimate that the proposed modifications reduce SoC area by up to approximately 5% compared to a baseline design. All artifacts will be released as open source, and we expect these findings to directly contribute to the evolution and ratification of RISC-V specifications, as well as to the design of future RISC-V SoCs."
    },
    {
      "paper_id": 1150,
      "domain": "cs",
      "subdomain": "cs.AR",
      "title": "Crypto-RV: High-Efficiency FPGA-Based RISC-V Cryptographic Co-Processor for IoT Security",
      "arxiv_id": "2602.04415v1",
      "score": 7.0,
      "abstract": "Cryptographic operations are critical for securing IoT, edge computing, and autonomous systems. However, current RISC-V platforms lack efficient hardware support for comprehensive cryptographic algorithm families and post-quantum cryptography. This paper presents Crypto-RV, a RISC-V co-processor architecture that unifies support for SHA-256, SHA-512, SM3, SHA3-256, SHAKE-128, SHAKE-256 AES-128, HARAKA-256, and HARAKA-512 within a single 64-bit datapath. Crypto-RV introduces three key architectural innovations: a high-bandwidth internal buffer (128x64-bit), cryptography-specialized execution units with four-stage pipelined datapaths, and a double-buffering mechanism with adaptive scheduling optimized for large-hash. Implemented on Xilinx ZCU102 FPGA at 160 MHz with 0.851 W dynamic power, Crypto-RV achieves 165 times to 1,061 times speedup over baseline RISC-V cores, 5.8 times to 17.4 times better energy efficiency compared to powerful CPUs. The design occupies only 34,704 LUTs, 37,329 FFs, and 22 BRAMs demonstrating viability for high-performance, energy-efficient cryptographic processing in resource-constrained IoT environments."
    },
    {
      "paper_id": 1154,
      "domain": "cs",
      "subdomain": "cs.AR",
      "title": "Ultrafast On-chip Online Learning via Spline Locality in Kolmogorov-Arnold Networks",
      "arxiv_id": "2602.02056v1",
      "score": 7.0,
      "abstract": "Ultrafast online learning is essential for high-frequency systems, such as controls for quantum computing and nuclear fusion, where adaptation must occur on sub-microsecond timescales. Meeting these requirements demands low-latency, fixed-precision computation under strict memory constraints, a regime in which conventional Multi-Layer Perceptrons (MLPs) are both inefficient and numerically unstable. We identify key properties of Kolmogorov-Arnold Networks (KANs) that align with these constraints. Specifically, we show that: (i) KAN updates exploiting B-spline locality are sparse, enabling superior on-chip resource scaling, and (ii) KANs are inherently robust to fixed-point quantization. By implementing fixed-point online training on Field-Programmable Gate Arrays (FPGAs), a representative platform for on-chip computation, we demonstrate that KAN-based online learners are significantly more efficient and expressive than MLPs across a range of low-latency and resource-constrained tasks. To our knowledge, this work is the first to demonstrate model-free online learning at sub-microsecond latencies."
    },
    {
      "paper_id": 1162,
      "domain": "cs",
      "subdomain": "cs.AR",
      "title": "AutoGNN: End-to-End Hardware-Driven Graph Preprocessing for Enhanced GNN Performance",
      "arxiv_id": "2602.00803v1",
      "score": 7.0,
      "abstract": "Graph neural network (GNN) inference faces significant bottlenecks in preprocessing, which often dominate overall inference latency. We introduce AutoGNN, an FPGA-based accelerator designed to address these challenges by leveraging FPGA's reconfigurability and specialized components. AutoGNN adapts to diverse graph inputs, efficiently performing computationally intensive tasks such as graph conversion and sampling. By utilizing components like adder trees, AutoGNN executes reduction operations in constant time, overcoming the limitations of serialization and synchronization on GPUs.\n  AutoGNN integrates unified processing elements (UPEs) and single-cycle reducers (SCRs) to streamline GNN preprocessing. UPEs enable scalable parallel processing for edge sorting and unique vertex selection, while SCRs efficiently handle sequential tasks such as pointer array construction and subgraph reindexing. A user-level software framework dynamically profiles graph inputs, determines optimal configurations, and reprograms AutoGNN to handle varying workloads. Implemented on a 7$n$m enterprise FPGA, AutoGNN achieves up to 9.0$\\times$ and 2.1$\\times$ speedup compared to conventional and GPU-accelerated preprocessing systems, respectively, enabling high-performance GNN preprocessing across diverse datasets."
    },
    {
      "paper_id": 1175,
      "domain": "cs",
      "subdomain": "cs.MM",
      "title": "MS-SCANet: A Multiscale Transformer-Based Architecture with Dual Attention for No-Reference Image Quality Assessment",
      "arxiv_id": "2602.04032v1",
      "score": 7.0,
      "abstract": "We present the Multi-Scale Spatial Channel Attention Network (MS-SCANet), a transformer-based architecture designed for no-reference image quality assessment (IQA). MS-SCANet features a dual-branch structure that processes images at multiple scales, effectively capturing both fine and coarse details, an improvement over traditional single-scale methods. By integrating tailored spatial and channel attention mechanisms, our model emphasizes essential features while minimizing computational complexity. A key component of MS-SCANet is its cross-branch attention mechanism, which enhances the integration of features across different scales, addressing limitations in previous approaches. We also introduce two new consistency loss functions, Cross-Branch Consistency Loss and Adaptive Pooling Consistency Loss, which maintain spatial integrity during feature scaling, outperforming conventional linear and bilinear techniques. Extensive evaluations on datasets like KonIQ-10k, LIVE, LIVE Challenge, and CSIQ show that MS-SCANet consistently surpasses state-of-the-art methods, offering a robust framework with stronger correlations with subjective human scores."
    },
    {
      "paper_id": 1182,
      "domain": "cs",
      "subdomain": "cs.MM",
      "title": "One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation",
      "arxiv_id": "2602.02033v1",
      "score": 7.0,
      "abstract": "Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all\" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \\textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF."
    },
    {
      "paper_id": 1194,
      "domain": "cs",
      "subdomain": "cs.SD",
      "title": "Speaker-Aware Simulation Improves Conversational Speech Recognition",
      "arxiv_id": "2602.04776v1",
      "score": 7.0,
      "abstract": "Automatic speech recognition (ASR) for conversational speech remains challenging due to the limited availability of large-scale, well-annotated multi-speaker dialogue data and the complex temporal dynamics of natural interactions. Speaker-aware simulated conversations (SASC) offer an effective data augmentation strategy by transforming single-speaker recordings into realistic multi-speaker dialogues. However, prior work has primarily focused on English data, leaving questions about the applicability to lower-resource languages. In this paper, we adapt and implement the SASC framework for Hungarian conversational ASR. We further propose C-SASC, an extended variant that incorporates pause modeling conditioned on utterance duration, enabling a more faithful representation of local temporal dependencies observed in human conversation while retaining the simplicity and efficiency of the original approach. We generate synthetic Hungarian dialogues from the BEA-Large corpus and combine them with real conversational data for ASR training. Both SASC and C-SASC are evaluated extensively under a wide range of simulation configurations, using conversational statistics derived from CallHome, BEA-Dialogue, and GRASS corpora. Experimental results show that speaker-aware conversational simulation consistently improves recognition performance over naive concatenation-based augmentation. While the additional duration conditioning in C-SASC yields modest but systematic gains--most notably in character-level error rates--its effectiveness depends on the match between source conversational statistics and the target domain. Overall, our findings confirm the robustness of speaker-aware conversational simulation for Hungarian ASR and highlight the benefits and limitations of increasingly detailed temporal modeling in synthetic dialogue generation."
    },
    {
      "paper_id": 1235,
      "domain": "q-bio",
      "subdomain": "q-bio.NC",
      "title": "Differential Dynamic Causal Nets: Model Construction, Identification and Group Comparisons",
      "arxiv_id": "2601.21478v1",
      "score": 7.0,
      "abstract": "Pathophysiolpgical modelling of brain systems from microscale to macroscale remains difficult in group comparisons partly because of the infeasibility of modelling the interactions of thousands of neurons at the scales involved. Here, to address the challenge, we present a novel approach to construct differential causal networks directly from electroencephalogram (EEG) data. The proposed network is based on conditionally coupled neuronal circuits which describe the average behaviour of interacting neuron populations that contribute to observed EEG data. In the network, each node represents a parameterised local neural system while directed edges stand for node-wise connections with transmission parameters. The network is hierarchically structured in the sense that node and edge parameters are varying in subjects but follow a mixed-effects model. A novel evolutionary optimisation algorithm for parameter inference in the proposed method is developed using a loss function derived from Chen-Fliess expansions of stochastic differential equations. The method is demonstrated by application to the fitting of coupled Jansen-Rit local models. The performance of the proposed method is evaluated on both synthetic and real EEG data. In the real EEG data analysis, we track changes in the parameters that characterise dynamic causality within brains that demonstrate epileptic activity. We show evidence of network functional disruptions, due to imbalance of excitatory-inhibitory interneurons and altered epileptic brain connectivity, before and during seizure periods."
    },
    {
      "paper_id": 1289,
      "domain": "cond-mat",
      "subdomain": "cond-mat.str-el",
      "title": "Reducing the Computational Cost Scaling of Tensor Network Algorithms via Field-Programmable Gate Array Parallelism",
      "arxiv_id": "2602.05900v1",
      "score": 7.0,
      "abstract": "Improving the computational efficiency of quantum many-body calculations from a hardware perspective remains a critical challenge. Although field-programmable gate arrays (FPGAs) have recently been exploited to improve the computational scaling of algorithms such as Monte Carlo methods, their application to tensor network algorithms is still at an early stage. In this work, we propose a fine-grained parallel tensor network design based on FPGAs to substantially enhance the computational efficiency of two representative tensor network algorithms: the infinite time-evolving block decimation (iTEBD) and the higher-order tensor renormalization group (HOTRG). By employing a quad-tile partitioning strategy to decompose tensor elements and map them onto hardware circuits, our approach effectively translates algorithmic computational complexity into scalable hardware resource utilization, enabling an extremely high degree of parallelism on FPGAs. Compared with conventional CPU-based implementations, our scheme exhibits superior scalability in computation time, reducing the bond-dimension scaling of the computational cost from $O(D_b^3)$ to $O(D_b)$ for iTEBD and from $O(D_b^6)$ to $O(D_b^2)$ for HOTRG. This work provides a theoretical foundation for future hardware implementations of large-scale tensor network computations."
    },
    {
      "paper_id": 1291,
      "domain": "cond-mat",
      "subdomain": "cond-mat.str-el",
      "title": "Suppressed coarsening after an interaction quench in the Holstein chain",
      "arxiv_id": "2602.05815v1",
      "score": 7.0,
      "abstract": "We investigate the nonequilibrium dynamics induced by an interaction quench in the semiclassical Holstein model within the Ehrenfest nonadiabatic framework, which describes an isolated hybrid quantum-classical system with strictly conserved total energy. Focusing on the half-filled case, where the equilibrium ground state exhibits commensurate charge-density-wave (CDW) order for any nonzero coupling, we identify three distinct post-quench dynamical regimes as a function of the final electron-phonon coupling: a nonequilibrium metallic state without CDW order, an intermediate regime characterized by slow scale-invariant ordering dynamics, and a frozen CDW state with arrested coarsening and immobile kinks. We analyze the intermediate regime in detail and uncover an unconventional algebraic decay of the kink density, $n \\sim t^{-1/3}$, distinct from both ballistic annihilation and diffusive coarsening in classical dissipative systems. We show that this anomalous exponent arises from the hybrid nature of the dynamics: while the lattice evolves deterministically, the electronic degrees of freedom act as an effective internal bath that induces diffusive kink motion without energy dissipation. An effective reaction-diffusion description, incorporating both annihilation and elastic scattering of kinks, quantitatively accounts for the observed scaling behavior. Our results reveal a distinct coarsening mechanism in isolated hybrid systems, demonstrating how internal quantum dynamics can qualitatively reshape defect kinetics far from equilibrium."
    },
    {
      "paper_id": 1310,
      "domain": "cond-mat",
      "subdomain": "cond-mat.soft",
      "title": "Transport Properties of Active Particles Moving on Adjustable Networks",
      "arxiv_id": "2602.04732v1",
      "score": 7.0,
      "abstract": "Active adaptive matter has attracted considerable interest due to its rich, largely unexplained dynamics and its relevance to a wide range of synthetic and biological materials. An important subclass of such systems consists of active particles that can remodel the network in which they move. Here, we introduce a minimal yet versatile model of active particles moving on an adjustable network. In this model, particles undergo discrete run-and-tumble motion along the links of a triangular lattice and leave behind a trail of temporarily blocked links. These closed links cannot be traversed by other particles and reopen only after a characteristic healing time. The resulting trail-mediated blocking mechanism is fundamentally distinct from more familiar interactions such as excluded-volume effects. In the high-persistence limit, we find a qualitative contrast between the two mechanisms: while steric blocking leads to reduced diffusivity with increasing persistence, trail-induced blocking causes diffusivity to increase monotonically. We characterize this fundamental difference and the associated, unexpected transport properties, and discuss potential applications of our findings."
    },
    {
      "paper_id": 1343,
      "domain": "physics",
      "subdomain": "physics.acc-ph",
      "title": "Laboratory Tests of Laser Control of Electron Beams for Future Colliders",
      "arxiv_id": "2601.19865v1",
      "score": 7.0,
      "abstract": "Laser-driven Compton backscattering (CBS) has been proposed as method for controlling the intensity of colliding bunches in the FCC-ee so as to avoid the flip-flop instability caused by intensity asymmetry in colliding bunches. Laser-based collimation has also been proposed as an indestructible collimator for high-intensity electron beams. We have initiated a laboratory-based test program of these concepts with the E344 experiment at FACET-II. In this paper, we describe simulations of laser-beam interactions at FACET-II and the relevant scaling for FCC-ee. We also describe the experimental setup and diagnostics that will be used to make the measurements at FACET-II."
    },
    {
      "paper_id": 1346,
      "domain": "cs",
      "subdomain": "cs.ET",
      "title": "Adaptive controllable architecture of analog Ising machine",
      "arxiv_id": "2602.05595v1",
      "score": 7.0,
      "abstract": "As a quantum-inspired, non-traditional analog solver architecture, the analog Ising machine (AIM) has emerged as a distinctive computational paradigm to address the rapidly growing demand for computational power. However, the mathematical understanding of its principles, as well as the optimization of its solution speed and accuracy, remain unclear. In this work, we for the first time systematically discuss multiple implementations of AIM and establish a unified mathematical formulation. On this basis, by treating the binarization constraint of AIM (such as injection locking) as a Lagrange multiplier in optimization theory and combining it with a Lyapunov analysis from dynamical systems theory, an analytical framework for evaluating solution speed and accuracy is constructed, and further demonstrate that conventional AIMs possess a theoretical performance upper bound. Subsequently, by elevating the binarization constraint to a control variable, we propose the controllable analog Ising machine (CAIM), which integrates control Lyapunov functions and momentum-based optimization algorithms to realize adaptive sampling-feedback control, thereby surpassing the performance limits of conventional AIMs. In a proof-of-concept CAIM demonstration implemented using an FPGA-controlled LC-oscillator Ising machine, CAIM achieves a twofold speedup and a 7\\% improvement in accuracy over AIM on a 50-node all-to-all weighted MaxCut problem, validating both the effectiveness and interpretability of the proposed theoretical framework."
    },
    {
      "paper_id": 1354,
      "domain": "cs",
      "subdomain": "cs.ET",
      "title": "The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study",
      "arxiv_id": "2602.04164v1",
      "score": 7.0,
      "abstract": "This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety."
    },
    {
      "paper_id": 1360,
      "domain": "astro-ph",
      "subdomain": "astro-ph.GA",
      "title": "Tracing AGN Feedback Power with Cool/Warm Outflow Densities: Predictions and Observational Implications",
      "arxiv_id": "2602.05954v1",
      "score": 7.0,
      "abstract": "Winds launched at the scale of the accretion disc or dusty torus in Active Galactic Nuclei (AGN) are thought to drive energy-conserving outflows that shape galaxy evolution. The key signature of such outflows, the presence of a hot ($T \\gtrsim 10^9 \\, \\rm K$), shocked wind component, is hard to detect directly. Observations of AGN outflows typically probe a separate outflow phase: cool/warm gas with $T \\lesssim 10^5 \\, \\rm K$. Here, we show that the density of cool outflowing gas scales with AGN luminosity, serving as an indirect diagnostic of the elusive hot, shocked wind. We use hydrodynamic simulations with the moving-mesh code AREPO to target the interaction between a small-scale AGN wind of speed $\\approx 10^4 \\, \\rm km \\, s^{-1}$ and galactic discs containing an idealised, clumpy interstellar medium (ISM). Through a new refinement scheme targeting rapidly-cooling, fast-moving gas, our simulations reach a resolution of $\\lesssim 0.1 \\, \\rm pc$ in the cool, outflowing phase. We extract an ensemble of cool clouds from the AGN-driven outflows produced in our simulations, finding that their densities increase systematically with AGN wind power and AGN luminosity. Moreover, the mass distribution and internal properties of these cloudlets appear to be insensitive to the initial properties of the ISM, and shaped mainly by the dynamics of radiative, turbulent mixing layers. The increase in cool outflow density with kinetic wind power and AGN luminosity has profound implications for observational estimates of outflow rates and their scaling with AGN luminosity. Depending on the available outflow and density tracers, observationally-derived outflow rates may be overestimated by orders of magnitude."
    },
    {
      "paper_id": 1381,
      "domain": "eess",
      "subdomain": "eess.SY",
      "title": "Policy-Driven Orchestration Framework for Multi-Operator Non-Terrestrial Networks",
      "arxiv_id": "2602.05363v1",
      "score": 7.0,
      "abstract": "Non-terrestrial networks (NTNs) have gained significant attention for their scalability and wide coverage in next-generation communication systems. A large number of NTN nodes, such as satellites, are required to establish a global NTN, but not all operators have the capability to deploy such a system. Therefore, cooperation among multiple operators, facilitated by an orchestrator, enables the construction of virtually large-scale constellations. In this paper, we propose a weak-control-based orchestration framework that coordinates multiple NTN operators while ensuring that operations align with the policies of both the orchestrator and the individual operators. Unlike centralized orchestration frameworks, where the orchestrator determines the entire route from source to destination, the proposed framework allows each operator to select preferred routes from multiple candidates provided by the orchestrator. To evaluate the effectiveness of our proposed framework, we conducted numerical simulations under various scenarios and network configurations including dynamic NTN environments with time-varying topologies, showing that inter-operator cooperation improves the availability of feasible end-to-end routes. Furthermore, we analyzed the iterative negotiation process to address policy conflicts and quantitatively demonstrated the \"price of autonomy,\" where strict individual policies degrade global feasibility and performance. The results also demonstrate that outcomes of the proposed framework depend on the operators' policies and that hop count and latency increase as the number of operators grows. These findings validate the proposed framework's ability to deliver practical benefits of orchestrated multi-operator collaboration in future NTN environments."
    },
    {
      "paper_id": 1382,
      "domain": "quant-ph",
      "subdomain": "quant-ph",
      "title": "High-order dynamical decoupling in the weak-coupling regime",
      "arxiv_id": "2602.05343v1",
      "score": 7.0,
      "abstract": "We introduce a high-order dynamical decoupling (DD) scheme for arbitrary system-bath interactions in the weak-coupling regime. Given any decoupling group $\\mathcal G$ that averages the interaction to zero, our construction yields pulse sequences whose length scales as $\\mathcal{O}(|\\mathcal G| K)$, while canceling all error terms linear in the system-bath coupling strength up to order $K$ in the total evolution time. As a corollary, for an $n$-qubit system with $k$-local system-bath interactions, we obtain an $\\mathcal{O}(n^{k-1}K)$-pulse sequence, a significant improvement over existing schemes with $\\mathcal{O}(\\exp(n))$ pulses (for $k=\\mathcal{O}(1)$). The construction is obtained via a mapping to the continuous necklace-splitting problem, which asks how to cut a multi-colored interval into pieces that give each party the same share of every color. We provide explicit pulse sequences for suppressing general single-qubit decoherence, prove that the pulse count is asymptotically optimal, and verify the predicted error scaling in numerical simulations. For the same number of pulses, we observe that our sequences outperform the state-of-the-art Quadratic DD in the weak-coupling regime. We also note that the same construction extends to suppress slow, time-dependent Hamiltonian noise."
    },
    {
      "paper_id": 1400,
      "domain": "cs",
      "subdomain": "cs.AI",
      "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity",
      "arxiv_id": "2602.03794v1",
      "score": 7.0,
      "abstract": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling."
    },
    {
      "paper_id": 1402,
      "domain": "cs",
      "subdomain": "cs.CV",
      "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers",
      "arxiv_id": "2602.03510v1",
      "score": 7.0,
      "abstract": "Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders, yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability, we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion. Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch: under classifier-free guidance, nominal timesteps fail to track the effective SNR, causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning."
    },
    {
      "paper_id": 1420,
      "domain": "quant-ph",
      "subdomain": "quant-ph",
      "title": "Quantum Circuit Representation of Bosonic Matrix Functions",
      "arxiv_id": "2602.01868v1",
      "score": 7.0,
      "abstract": "Bosonic counting problems can be framed as estimation tasks of matrix functions such as the permanent, hafnian, and loop-hafnian, depending on the underlying bosonic network. Remarkably, the same functions also arise in spin models, including the Ising and Heisenberg models, where distinct interaction structures correspond to different matrix functions. This correspondence has been used to establish the classical hardness of simulating interacting spin systems by relating their output distributions to #P-hard quantities. Previous works, however, have largely been restricted to bipartite spin interactions, where transition amplitudes, which provide the leading-order contribution to the output probabilities, are proportional to the permanent. In this work, we extend the Ising model construction to arbitrary interaction networks and show that transition amplitudes of the Ising Hamiltonian are proportional to the hafnian and the loop-hafnian. The loop-hafnian generalizes both the permanent and hafnian, but unlike these cases, loop-hafnian-based states require Dicke-like superpositions, making the design of corresponding quantum circuits non-trivial. Our results establish a unified framework linking bosonic networks of single photons and Gaussian states with quantum spin dynamics and matrix functions. This unification not only broadens the theoretical foundation of quantum circuit models but also highlights new, diverse, and classically intractable applications."
    },
    {
      "paper_id": 1442,
      "domain": "cs",
      "subdomain": "cs.CL",
      "title": "LegalOne: A Family of Foundation Models for Reliable Legal Reasoning",
      "arxiv_id": "2602.00642v2",
      "score": 7.0,
      "abstract": "While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications."
    },
    {
      "paper_id": 1458,
      "domain": "math",
      "subdomain": "math.NA",
      "title": "FNWoS: Fractional Neural Walk-on-Spheres Methods for High-Dimensional PDEs Driven by $\u03b1$-stable L\u00e9vy Process on Irregular Domains",
      "arxiv_id": "2601.22942v1",
      "score": 7.0,
      "abstract": "In this paper, we develop a highly parallel and derivative-free fractional neural walk-on-spheres method (FNWoS) for solving high-dimensional fractional Poisson equations on irregular domains. We first propose a simplified fractional walk-on-spheres (FWoS) scheme that replaces the high-dimensional normalized weight integral with a constant weight and adopts a correspondingly simpler sampling density, substantially reducing per-trajectory cost. To mitigate the slow convergence of standard Monte Carlo sampling, FNWoS is then proposed via integrating this simplified FWoS estimator, derived from the Feynman-Kac representation, with a neural network surrogate. By amortizing sampling effort over the entire domain during training, FNWoS achieves more accurate evaluation at arbitrary query points with dramatically fewer trajectories than classical FWoS. To further enhance efficiency in regimes where the fractional order $\u03b1$ is close to 2 and trajectories become excessively long, we introduce a truncated path strategy with a prescribed maximum step count. Building on this, we propose a buffered supervision mechanism that caches training pairs and progressively refines their Monte Carlo targets during training, removing the need to precompute a highly accurate training set and yielding the buffered fractional neural walk-on-spheres method (BFNWoS). Extensive numerical experiments, including tests on irregular domains and problems with dimensions up to $1000$, demonstrate the accuracy, scalability, and computational efficiency of the proposed methods."
    },
    {
      "paper_id": 1468,
      "domain": "eess",
      "subdomain": "eess.IV",
      "title": "Active Learning-Driven Lightweight YOLOv9: Enhancing Efficiency in Smart Agriculture",
      "arxiv_id": "2601.22732v1",
      "score": 7.0,
      "abstract": "This study addresses the demand for real-time detection of tomatoes and tomato flowers by agricultural robots deployed on edge devices in greenhouse environments. Under practical imaging conditions, object detection systems often face challenges such as large scale variations caused by varying camera distances, severe occlusion from plant structures, and highly imbalanced class distributions. These factors make conventional object detection approaches that rely on fully annotated datasets difficult to simultaneously achieve high detection accuracy and deployment efficiency. To overcome these limitations, this research proposes an active learning driven lightweight object detection framework, integrating data analysis, model design, and training strategy. First, the size distribution of objects in raw agricultural images is analyzed to redefine an operational target range, thereby improving learning stability under real-world conditions. Second, an efficient feature extraction module is incorporated to reduce computational cost, while a lightweight attention mechanism is introduced to enhance feature representation under multi-scale and occluded scenarios. Finally, an active learning strategy is employed to iteratively select high-information samples for annotation and training under a limited labeling budget, effectively improving the recognition performance of minority and small-object categories. Experimental results demonstrate that, while maintaining a low parameter count and inference cost suitable for edge-device deployment, the proposed method effectively improves the detection performance of tomatoes and tomato flowers in raw images. Under limited annotation conditions, the framework achieves an overall detection accuracy of 67.8% mAP, validating its practicality and feasibility for intelligent agricultural applications."
    },
    {
      "paper_id": 1471,
      "domain": "cs",
      "subdomain": "cs.LG",
      "title": "EUGens: Efficient, Unified, and General Dense Layers",
      "arxiv_id": "2601.22563v2",
      "score": 7.0,
      "abstract": "Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \\textbf{E}fficient, \\textbf{U}nified and \\textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \\textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \\textbf{27}\\%) and memory efficiency (up to \\textbf{30}\\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios."
    },
    {
      "paper_id": 1499,
      "domain": "cs",
      "subdomain": "cs.LG",
      "title": "Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine",
      "arxiv_id": "2602.06955v1",
      "score": 7.0,
      "abstract": "Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature selection, and preprocessing refinement. Rather than relying on conventional sampling techniques that may introduce bias or cause information loss, the optimized EBM achieves an effective balance between accuracy and interpretability, enabling precise detection of fraudulent transactions while providing actionable insights into feature importance and interaction effects. Furthermore, the Taguchi method is employed to optimize both the sequence of data scalers and model hyperparameters, ensuring robust, reproducible, and systematically validated performance improvements. Experimental evaluation on benchmark credit card data yields an ROC-AUC of 0.983, surpassing prior EBM baselines (0.975) and outperforming Logistic Regression, Random Forest, XGBoost, and Decision Tree models. These results highlight the potential of interpretable machine learning and data-driven optimization for advancing trustworthy fraud analytics in financial systems."
    },
    {
      "paper_id": 1508,
      "domain": "cs",
      "subdomain": "cs.LG",
      "title": "When RL Meets Adaptive Speculative Training: A Unified Training-Serving System",
      "arxiv_id": "2602.06932v1",
      "score": 7.0,
      "abstract": "Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before deployment; (2) delayed utility feedback, since the true end-to-end decoding speedup is only known after training and cannot be inferred reliably from acceptance rate alone due to model-architecture and system-level overheads; and (3) domain-drift degradation, as the target model is repurposed to new domains and the speculator becomes stale and less effective.\n  To address these issues, we present Aurora, a unified training-serving system that closes the loop by continuously learning a speculator directly from live inference traces. Aurora reframes online speculator learning as an asynchronous reinforcement-learning problem: accepted tokens provide positive feedback, while rejected speculator proposals provide implicit negative feedback that we exploit to improve sample efficiency. Our design integrates an SGLang-based inference server with an asynchronous training server, enabling hot-swapped speculator updates without service interruption. Crucially, Aurora supports day-0 deployment: a speculator can be served immediately and rapidly adapted to live traffic, improving system performance while providing immediate utility feedback. Across experiments, Aurora achieves a 1.5x day-0 speedup on recently released frontier models (e.g., MiniMax M2.1 229B and Qwen3-Coder-Next 80B). Aurora also adapts effectively to distribution shifts in user traffic, delivering an additional 1.25x speedup over a well-trained but static speculator on widely used models (e.g., Qwen3 and Llama3)."
    },
    {
      "paper_id": 1530,
      "domain": "cs",
      "subdomain": "cs.AI",
      "title": "Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping",
      "arxiv_id": "2602.06850v1",
      "score": 7.0,
      "abstract": "While modern text-to-image models excel at prompt-based generation, they often lack the fine-grained control necessary for specific user requirements like spatial layouts or subject appearances. Multi-condition control addresses this, yet its integration into Diffusion Transformers (DiTs) is bottlenecked by the conventional ``concatenate-and-attend'' strategy, which suffers from quadratic computational and memory overhead as the number of conditions scales. Our analysis reveals that much of this cross-modal interaction is spatially or semantically redundant. To this end, we propose Position-aligned and Keyword-scoped Attention (PKA), a highly efficient framework designed to eliminate these redundancies. Specifically, Position-Aligned Attention (PAA) linearizes spatial control by enforcing localized patch alignment, while Keyword-Scoped Attention (KSA) prunes irrelevant subject-driven interactions via semantic-aware masking. To facilitate efficient learning, we further introduce a Conditional Sensitivity-Aware Sampling (CSAS) strategy that reweights the training objective towards critical denoising phases, drastically accelerating convergence and enhancing conditional fidelity. Empirically, PKA delivers a 10.0$\\times$ inference speedup and a 5.1$\\times$ VRAM saving, providing a scalable and resource-friendly solution for high-fidelity multi-conditioned generation."
    },
    {
      "paper_id": 1531,
      "domain": "cs",
      "subdomain": "cs.LG",
      "title": "A Cycle-Consistent Graph Surrogate for Full-Cycle Left Ventricular Myocardial Biomechanics",
      "arxiv_id": "2602.06884v1",
      "score": 7.0,
      "abstract": "Image-based patient-specific simulation of left ventricular (LV) mechanics is valuable for understanding cardiac function and supporting clinical intervention planning, but conventional finite-element analysis (FEA) is computationally intensive. Current graph-based surrogates do not have full-cycle prediction capabilities, and physics-informed neural networks often struggle to converge on complex cardiac geometries. We present CardioGraphFENet (CGFENet), a unified graph-based surrogate for rapid full-cycle estimation of LV myocardial biomechanics, supervised by a large FEA simulation dataset. The proposed model integrates (i) a global--local graph encoder to capture mesh features with weak-form-inspired global coupling, (ii) a gated recurrent unit-based temporal encoder conditioned on the target volume-time signal to model cycle-coherent dynamics, and (iii) a cycle-consistent bidirectional formulation for both loading and inverse unloading within a single framework. These strategies enable high fidelity with respect to traditional FEA ground truths and produce physiologically plausible pressure-volume loops that match FEA results when coupled with a lumped-parameter model. In particular, the cycle-consistency strategy enables a significant reduction in FEA supervision with only minimal loss in accuracy."
    },
    {
      "paper_id": 1543,
      "domain": "stat",
      "subdomain": "stat.ML",
      "title": "Missing At Random as Covariate Shift: Correcting Bias in Iterative Imputation",
      "arxiv_id": "2602.06713v1",
      "score": 7.0,
      "abstract": "Accurate imputation of missing data is critical to downstream machine learning performance. We formulate missing data imputation as a risk minimisation problem, which highlights a covariate shift between the observed and unobserved data distributions. This covariate shift induced bias is not accounted for by popular imputation methods and leads to suboptimal performance. In this paper, we derive theoretically valid importance weights that correct for the induced distributional bias. Furthermore, we propose a novel imputation algorithm that jointly estimates both the importance weights and imputation models, enabling bias correction throughout the imputation process. Empirical results across benchmark datasets show reductions in root mean squared error and Wasserstein distance of up to 7% and 20%, respectively, compared to otherwise identical unweighted methods."
    },
    {
      "paper_id": 1545,
      "domain": "stat",
      "subdomain": "stat.ML",
      "title": "Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning",
      "arxiv_id": "2602.06584v1",
      "score": 7.0,
      "abstract": "Standard chain-of-thought reasoning generates a solution in a single forward pass, committing irrevocably to each token and lacking a mechanism to recover from early errors. We introduce Inference-Time Rethinking, a generative framework that enables iterative self-correction by decoupling declarative latent thought vectors from procedural generation. We factorize reasoning into a continuous latent thought vector (what to reason about) and a decoder that verbalizes the trace conditioned on this vector (how to reason). Beyond serving as a declarative buffer, latent thought vectors compress the reasoning structure into a continuous representation that abstracts away surface-level token variability, making gradient-based optimization over reasoning strategies well-posed. Our prior model maps unstructured noise to a learned manifold of valid reasoning patterns, and at test time we employ a Gibbs-style procedure that alternates between generating a candidate trace and optimizing the latent vector to better explain that trace, effectively navigating the latent manifold to refine the reasoning strategy. Training a 0.2B-parameter model from scratch on GSM8K, our method with 30 rethinking iterations surpasses baselines with 10 to 15 times more parameters, including a 3B counterpart. This result demonstrates that effective mathematical reasoning can emerge from sophisticated inference-time computation rather than solely from massive parameter counts."
    },
    {
      "paper_id": 1569,
      "domain": "cs",
      "subdomain": "cs.AI",
      "title": "Bridging 6G IoT and AI: LLM-Based Efficient Approach for Physical Layer's Optimization Tasks",
      "arxiv_id": "2602.06819v1",
      "score": 7.0,
      "abstract": "This paper investigates the role of large language models (LLMs) in sixth-generation (6G) Internet of Things (IoT) networks and proposes a prompt-engineering-based real-time feedback and verification (PE-RTFV) framework that perform physical-layer's optimization tasks through an iteratively process. By leveraging the naturally available closed-loop feedback inherent in wireless communication systems, PE-RTFV enables real-time physical-layer optimization without requiring model retraining. The proposed framework employs an optimization LLM (O-LLM) to generate task-specific structured prompts, which are provided to an agent LLM (A-LLM) to produce task-specific solutions. Utilizing real-time system feedback, the O-LLM iteratively refines the prompts to guide the A-LLM toward improved solutions in a gradient-descent-like optimization process. We test PE-RTFV approach on wireless-powered IoT testbed case study on user-goal-driven constellation design through semantically solving rate-energy (RE)-region optimization problem which demonstrates that PE-RTFV achieves near-genetic-algorithm performance within only a few iterations, validating its effectiveness for complex physical-layer optimization tasks in resource-constrained IoT networks."
    },
    {
      "paper_id": 1570,
      "domain": "cs",
      "subdomain": "cs.AI",
      "title": "Wild Guesses and Mild Guesses in Active Concept Learning",
      "arxiv_id": "2602.06818v1",
      "score": 7.0,
      "abstract": "Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule or category. Active concept learning must balance informativeness of queries against the stability of the learner that generates and scores hypotheses. We study this trade-off in a neuro-symbolic Bayesian learner whose hypotheses are executable programs proposed by a large language model (LLM) and reweighted by Bayesian updating. We compare a Rational Active Learner that selects queries to maximize approximate expected information gain (EIG) and the human-like Positive Test Strategy (PTS) that queries instances predicted to be positive under the current best hypothesis. Across concept-learning tasks in the classic Number Game, EIG is effective when falsification is necessary (e.g., compound or exception-laden rules), but underperforms on simple concepts. We trace this failure to a support mismatch between the EIG policy and the LLM proposal distribution: highly diagnostic boundary queries drive the posterior toward regions where the generator produces invalid or overly specific programs, yielding a support-mismatch trap in the particle approximation. PTS is information-suboptimal but tends to maintain proposal validity by selecting \"safe\" queries, leading to faster convergence on simple rules. Our results suggest that \"confirmation bias\" may not be a cognitive error, but rather a rational adaptation for maintaining tractable inference in the sparse, open-ended hypothesis spaces characteristic of human thought."
    }
  ]
}